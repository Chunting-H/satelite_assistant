# backend/src/graph/workflow_streaming.py - ä¿®å¤æ‰€æœ‰æ„å›¾çš„æµå¼è¾“å‡º
import os
import sys
import logging
import json
import requests
import uuid
import numpy as np
import asyncio
from typing import Dict, List, Any, Optional, Tuple, Callable, Union
from pathlib import Path
import time
from dotenv import load_dotenv, find_dotenv
import re

# è®¾ç½®é¡¹ç›®æ ¹ç›®å½•
dotenv_path = find_dotenv()
if dotenv_path:
    project_root = Path(dotenv_path).parent
else:
    current_file = Path(__file__).resolve()
    project_root = current_file.parent.parent.parent

sys.path.append(str(project_root))

if dotenv_path:
    load_dotenv(dotenv_path=dotenv_path, override=True)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger(__name__)

# å¯¼å…¥é¡¹ç›®ç»„ä»¶
from backend.src.graph.state import WorkflowState
from backend.src.tools.knowledge_tools import retrieve_knowledge_for_workflow
# å¯¼å…¥æµå¼æ–¹æ¡ˆç”ŸæˆèŠ‚ç‚¹ - ä¼˜å…ˆä½¿ç”¨å¸¦ç¼“å†²çš„ç‰ˆæœ¬
# from backend.src.graph.nodes.buffered_streaming_planning_nodes import (
#     generate_constellation_plan_streaming,
#     optimize_constellation_plan_streaming
# )
from backend.src.graph.nodes.direct_streaming_planning_nodes import (
    generate_constellation_plan_streaming,
    optimize_constellation_plan_streaming
)
from backend.src.tools.satellite_extractor import (
    extract_satellite_names,
    extract_satellite_names_from_messages,
    extract_satellite_names_with_cache,
    extract_satellites_from_composition,
    extract_satellites_from_table,
    extract_satellites_two_phase,
    normalize_satellite_name
)

STREAMING_NODES_AVAILABLE = True
logger.info("æˆåŠŸå¯¼å…¥å¸¦ç¼“å†²çš„æµå¼æ–¹æ¡ˆç”ŸæˆèŠ‚ç‚¹")

# DeepSeek APIé…ç½®
DEEPSEEK_API_KEY = os.environ.get("DEEPSEEK_API_KEY", "")

if not DEEPSEEK_API_KEY:
    logger.warning("DEEPSEEK_API_KEYç¯å¢ƒå˜é‡æœªè®¾ç½®ï¼Œæ„å›¾åˆ†æå°†æ— æ³•ä½¿ç”¨LLM")


def convert_to_json_serializable(obj):
    """é€’å½’åœ°å°†å¯¹è±¡è½¬æ¢ä¸ºJSONå¯åºåˆ—åŒ–çš„æ ¼å¼"""
    if isinstance(obj, dict):
        return {key: convert_to_json_serializable(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [convert_to_json_serializable(item) for item in obj]
    elif isinstance(obj, tuple):
        return [convert_to_json_serializable(item) for item in obj]
    elif isinstance(obj, set):
        return [convert_to_json_serializable(item) for item in obj]
    elif isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif hasattr(obj, '__dict__'):
        return convert_to_json_serializable(obj.__dict__)
    else:
        return obj


def safe_json_dumps(obj, **kwargs):
    """å®‰å…¨çš„JSONåºåˆ—åŒ–å‡½æ•°"""
    try:
        return json.dumps(obj, **kwargs)
    except TypeError as e:
        logger.warning(f"ç›´æ¥åºåˆ—åŒ–å¤±è´¥: {str(e)}, å°è¯•è½¬æ¢ååºåˆ—åŒ–")
        converted_obj = convert_to_json_serializable(obj)
        return json.dumps(converted_obj, **kwargs)


async def extract_satellites_from_plan(plan_content: str) -> List[str]:
    """ä»æ–¹æ¡ˆå†…å®¹ä¸­æå–å«æ˜Ÿåç§° - ä½¿ç”¨ç»Ÿä¸€çš„æå–å™¨"""
    if not plan_content:
        logger.warning("æ–¹æ¡ˆå†…å®¹ä¸ºç©ºï¼Œæ— æ³•æå–å«æ˜Ÿ")
        return []

    logger.info(f"ğŸ” å¼€å§‹ä»æ–¹æ¡ˆä¸­æå–å«æ˜Ÿï¼Œå†…å®¹é•¿åº¦: {len(plan_content)}")

    # ä½¿ç”¨ç»Ÿä¸€çš„æå–å‡½æ•°
    satellites = await extract_satellite_names_with_cache(plan_content)

    logger.info(f"âœ… æœ€ç»ˆæå–åˆ°çš„å«æ˜Ÿåˆ—è¡¨: {satellites}")
    return satellites


class StreamingContentSender:
    """æµå¼å†…å®¹å‘é€å™¨ - ç”¨äºæ¨¡æ‹Ÿå’ŒçœŸå®çš„æµå¼è¾“å‡º"""

    def __init__(self, websocket_callback=None):
        self.websocket_callback = websocket_callback

    async def send_content_streaming(self, content: str, chunk_size: int = 15, delay: float = 0.1):
        """ä»¥æµå¼æ–¹å¼å‘é€å†…å®¹"""
        if not content or not self.websocket_callback:
            return

        # æŒ‰å¥å­æˆ–è‡ªç„¶åˆ†æ®µç‚¹åˆ†å‰²å†…å®¹
        segments = self._split_content_naturally(content)
        accumulated_content = ""

        for segment in segments:
            accumulated_content += segment

            await self.websocket_callback({
                "type": "response_chunk",
                "content": segment,
                "accumulated_content": accumulated_content,
                "chunk_type": "streaming_response"
            })

            # æ ¹æ®å†…å®¹é•¿åº¦è°ƒæ•´å»¶è¿Ÿ
            segment_delay = min(delay * len(segment) / 10, delay * 3)
            await asyncio.sleep(segment_delay)

    def _split_content_naturally(self, content: str) -> List[str]:
        """è‡ªç„¶åœ°åˆ†å‰²å†…å®¹ä¸ºæ®µè½"""
        import re

        # æŒ‰æ®µè½åˆ†å‰²
        paragraphs = content.split('\n\n')
        segments = []

        for paragraph in paragraphs:
            if not paragraph.strip():
                continue

            # å¦‚æœæ®µè½å¾ˆé•¿ï¼ŒæŒ‰å¥å­åˆ†å‰²
            if len(paragraph) > 100:
                sentences = re.split(r'([ã€‚ï¼ï¼Ÿ\.!?])', paragraph)
                current_segment = ""

                for i in range(0, len(sentences), 2):
                    sentence = sentences[i]
                    punctuation = sentences[i + 1] if i + 1 < len(sentences) else ""

                    current_segment += sentence + punctuation

                    # å¦‚æœæ®µè½è¾¾åˆ°åˆé€‚é•¿åº¦æˆ–æ˜¯æœ€åä¸€ä¸ªå¥å­
                    if len(current_segment) >= 30 or i >= len(sentences) - 2:
                        segments.append(current_segment)
                        current_segment = ""
            else:
                segments.append(paragraph)

            # æ®µè½ä¹‹é—´æ·»åŠ æ¢è¡Œ
            if paragraph != paragraphs[-1]:
                segments.append('\n\n')

        return [seg for seg in segments if seg.strip()]


class StreamingWorkflowManager:
    """å¢å¼ºçš„æµå¼å·¥ä½œæµç®¡ç†å™¨ - æ”¯æŒæ‰€æœ‰æ„å›¾çš„æµå¼è¾“å‡º"""

    def __init__(self, websocket_callback=None):
        self.websocket_callback = websocket_callback
        self.sent_thinking_steps = set()
        self.current_session_id = str(uuid.uuid4())
        self.content_sender = StreamingContentSender(websocket_callback)

    async def send_status(self, message_type: str, data: Dict[str, Any]):
        """ç«‹å³å‘é€çŠ¶æ€æ›´æ–°"""
        if self.websocket_callback:
            try:
                if message_type == "thinking_step":
                    step_key = f"{data.get('step', '')}__{data.get('message', '')}"
                    if step_key in self.sent_thinking_steps:
                        return
                    self.sent_thinking_steps.add(step_key)

                await self.websocket_callback({
                    "type": message_type,
                    "timestamp": time.time(),
                    **data
                })
                await asyncio.sleep(0.05)
            except Exception as e:
                logger.error(f"å‘é€WebSocketæ¶ˆæ¯å¤±è´¥: {str(e)}")

    def reset_session(self):
        """é‡ç½®ä¼šè¯"""
        self.sent_thinking_steps.clear()
        self.current_session_id = str(uuid.uuid4())
        logger.info(f"é‡ç½®æ€è€ƒæ­¥éª¤ä¼šè¯: {self.current_session_id}")

    def _smart_truncate_history(self, history_messages: List[Dict], current_message: str, max_messages: int = 20) -> \
            List[Dict]:
        """æ™ºèƒ½æˆªæ–­å¯¹è¯å†å²"""
        if len(history_messages) <= max_messages:
            return history_messages

        # æå–å½“å‰æ¶ˆæ¯çš„å…³é”®è¯
        current_keywords = self._extract_keywords(current_message)

        # è®¡ç®—æ¯æ¡å†å²æ¶ˆæ¯çš„ç›¸å…³æ€§åˆ†æ•°
        message_scores = []
        for i, msg in enumerate(history_messages):
            if msg["role"] == "user":
                relevance_score = self._calculate_relevance(msg["content"], current_keywords)
                message_scores.append((i, relevance_score))

        # æŒ‰ç›¸å…³æ€§æ’åºï¼Œä¿ç•™æœ€ç›¸å…³çš„æ¶ˆæ¯
        message_scores.sort(key=lambda x: x[1], reverse=True)

        # é€‰æ‹©æœ€ç›¸å…³çš„æ¶ˆæ¯ï¼Œä½†ç¡®ä¿åŒ…å«æœ€è¿‘çš„å¯¹è¯
        selected_indices = set()

        # é¦–å…ˆä¿ç•™æœ€è¿‘çš„å¯¹è¯ï¼ˆæœ€å5è½®ï¼‰
        recent_count = min(5, len(history_messages) // 2)
        for i in range(len(history_messages) - recent_count, len(history_messages)):
            selected_indices.add(i)

        # ç„¶åæ·»åŠ æœ€ç›¸å…³çš„æ¶ˆæ¯
        for i, score in message_scores:
            if len(selected_indices) < max_messages and i not in selected_indices:
                selected_indices.add(i)

        # æŒ‰åŸå§‹é¡ºåºè¿”å›é€‰ä¸­çš„æ¶ˆæ¯
        selected_messages = [history_messages[i] for i in sorted(selected_indices)]

        logger.info(f"æ™ºèƒ½æˆªæ–­ï¼šä»{len(history_messages)}æ¡æ¶ˆæ¯ä¸­é€‰æ‹©{len(selected_messages)}æ¡æœ€ç›¸å…³çš„æ¶ˆæ¯")
        return selected_messages

    def _extract_keywords(self, text: str) -> List[str]:
        """æå–æ–‡æœ¬å…³é”®è¯ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
        # ç®€å•çš„å…³é”®è¯æå–ï¼šå»é™¤åœç”¨è¯ï¼Œä¿ç•™é‡è¦è¯æ±‡
        stop_words = {'çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æˆ‘', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'äºº', 'éƒ½', 'ä¸€', 'ä¸€ä¸ª', 'ä¸Š', 'ä¹Ÿ', 'å¾ˆ',
                      'åˆ°', 'è¯´', 'è¦', 'å»', 'ä½ ', 'ä¼š', 'ç€', 'æ²¡æœ‰', 'çœ‹', 'å¥½', 'è‡ªå·±', 'è¿™'}

        # ç®€å•çš„åˆ†è¯ï¼ˆæŒ‰ç©ºæ ¼å’Œæ ‡ç‚¹åˆ†å‰²ï¼‰
        import re
        words = re.findall(r'[\u4e00-\u9fff]+|[a-zA-Z]+', text.lower())

        # è¿‡æ»¤åœç”¨è¯å’ŒçŸ­è¯
        keywords = [word for word in words if word not in stop_words and len(word) > 1]

        return keywords[:10]  # æœ€å¤šè¿”å›10ä¸ªå…³é”®è¯

    def _calculate_relevance(self, text: str, keywords: List[str]) -> float:
        """è®¡ç®—æ–‡æœ¬ä¸å…³é”®è¯çš„ç›¸å…³æ€§åˆ†æ•°"""
        if not keywords:
            return 0.0

        text_lower = text.lower()
        matches = sum(1 for keyword in keywords if keyword in text_lower)
        return matches / len(keywords)

    async def generate_response_streaming(self, state: WorkflowState) -> WorkflowState:
        """æµå¼å“åº”ç”Ÿæˆ - ç§»é™¤å¯è§†åŒ–æ•°æ®å¤„ç†"""
        intent = state.metadata.get("intent", "unknown")

        await self.send_status("thinking_step", {
            "step": "å“åº”ç”Ÿæˆ",
            "message": f"æ­£åœ¨ä¸º '{intent}' æ„å›¾ç”Ÿæˆå“åº”"
        })

        # ç”Ÿæˆå“åº”å†…å®¹
        response_content = ""

        if intent == "generate_plan" and state.main_plan:
            response_content = str(state.main_plan) if not isinstance(state.main_plan, str) else state.main_plan

            # ğŸ”§ ç§»é™¤å¯è§†åŒ–æ•°æ®ç”Ÿæˆé€»è¾‘
            # ä»…ç¡®ä¿å«æ˜Ÿä¿¡æ¯å·²ç»åœ¨çŠ¶æ€ä¸­
            # if not hasattr(state, 'extracted_satellites') or not state.extracted_satellites:
            #     # æ”¹ä¸ºåŒæ­¥è°ƒç”¨
            #     from backend.src.tools.satellite_extractor import extract_satellites_from_composition
            #     extracted_satellites = extract_satellites_from_composition(response_content)
            #     if extracted_satellites:
            #         state.set_extracted_satellites(extracted_satellites)
            #         state.metadata['extracted_satellites'] = extracted_satellites
            #         logger.info(f"âœ… ä»æ–°æ–¹æ¡ˆä¸­æå–åˆ°å«æ˜Ÿ: {extracted_satellites}")
            #     else:
            #         logger.warning("âš ï¸ æœªèƒ½ä»æ–¹æ¡ˆä¸­æå–åˆ°å«æ˜Ÿä¿¡æ¯")

        elif intent == "optimize_plan" and state.main_plan:
            response_content = str(state.main_plan) if not isinstance(state.main_plan, str) else state.main_plan

            # ä»ä¼˜åŒ–åçš„æ–¹æ¡ˆä¸­æå–å«æ˜Ÿ
            # extracted_satellites = extract_satellites_from_plan(response_content)
            # if extracted_satellites:
            #     state.set_extracted_satellites(extracted_satellites)

        elif intent == "provide_info":
            response_content = await self.generate_info_response_streaming(state)
        else:
            response_content = await self.generate_general_response_streaming(state)

        # ç¡®ä¿æœ‰æœ‰æ•ˆå“åº”
        if not response_content or response_content.strip() == "":
            response_content = "æŠ±æ­‰ï¼Œæœªèƒ½ç”Ÿæˆæœ‰æ•ˆå›å¤ã€‚è¯·å°è¯•é‡æ–°æè¿°æ‚¨çš„éœ€æ±‚ã€‚"

        # æ·»åŠ åˆ°çŠ¶æ€
        state.add_message("assistant", response_content)

        await self.send_status("thinking_step", {
            "step": "å“åº”å‡†å¤‡å®Œæˆ",
            "message": "å“åº”å†…å®¹å·²å‡†å¤‡å®Œæ¯•"
        })

        state.current_stage = "complete"
        return state

    async def generate_intent_confirmation_message(self, intent: str, user_message: str) -> str:
        """ç”Ÿæˆæ„å›¾ç¡®è®¤æ¶ˆæ¯ - ä»…ç”¨äºæ–¹æ¡ˆç”Ÿæˆå’Œä¼˜åŒ–"""
        confirmation_messages = {
            "generate_plan": f"""ğŸ“ åŸºäºæ‚¨çš„æè¿°ï¼Œæˆ‘å‡†å¤‡ä¸ºæ‚¨ï¼š
    1ã€ ğŸ›°ï¸ è®¾è®¡å®šåˆ¶åŒ–çš„è™šæ‹Ÿæ˜Ÿåº§ç»„åˆ
    2ã€ ğŸ“Š åˆ†ææœ€é€‚åˆçš„å«æ˜Ÿé…ç½®
    3ã€ ğŸ“ˆ ç”Ÿæˆè¯¦ç»†çš„ç›‘æµ‹æ–¹æ¡ˆ
    è¯·å†ä¸€æ¬¡ç¡®è®¤ï¼šæ˜¯å¦éœ€è¦æˆ‘ä¸ºæ‚¨ç”Ÿæˆè™šæ‹Ÿæ˜Ÿåº§æ–¹æ¡ˆï¼Ÿ(æ˜¯/å¦)""",

            "optimize_plan": f"""æˆ‘æ³¨æ„åˆ°æ‚¨æƒ³è¦ä¼˜åŒ–ç°æœ‰çš„è™šæ‹Ÿæ˜Ÿåº§æ–¹æ¡ˆã€‚
    ğŸ”§ ä¼˜åŒ–æ„å›¾ï¼š
    æ ¹æ®æ‚¨çš„åé¦ˆã€Œ{user_message}ã€ï¼Œæˆ‘ç†è§£æ‚¨å¸Œæœ›ï¼š
    1ã€ è°ƒæ•´å½“å‰æ–¹æ¡ˆçš„æŸäº›å‚æ•°
    2ã€ æ”¹è¿›å«æ˜Ÿç»„åˆé…ç½®
    3ã€ ä¼˜åŒ–ç›‘æµ‹æ•ˆæœ
    è¯·ç¡®è®¤ï¼šæ˜¯å¦éœ€è¦æˆ‘ä¼˜åŒ–å½“å‰æ–¹æ¡ˆ(æ˜¯/å¦)ï¼Ÿ"""
        }

        # é»˜è®¤è¿”å›generate_plançš„ç¡®è®¤æ¶ˆæ¯
        return confirmation_messages.get(intent, confirmation_messages["generate_plan"])

    async def handle_intent_confirmation(self, state: WorkflowState, user_response: str) -> Tuple[bool, Optional[str]]:
        """å¤„ç†ç”¨æˆ·çš„æ„å›¾ç¡®è®¤å›å¤

        è¿”å›: (æ˜¯å¦ç¡®è®¤, æ–°æ„å›¾)
        """
        response_lower = user_response.lower()

        # ç¡®è®¤å…³é”®è¯
        confirm_keywords = ['æ˜¯', 'å¯¹', 'ç¡®è®¤', 'æ²¡é”™', 'æ˜¯çš„', 'yes', 'ok', 'å¥½çš„', 'å¯ä»¥', 'å¼€å§‹']
        deny_keywords = ['ä¸æ˜¯', 'ä¸å¯¹', 'å¦', 'ä¸', 'no', 'é”™äº†', 'ä¸ç”¨']

        # æ£€æŸ¥æ˜¯å¦ç¡®è®¤
        if any(keyword in response_lower for keyword in confirm_keywords):
            return True, None

        # æ£€æŸ¥æ˜¯å¦å¦è®¤
        if any(keyword in response_lower for keyword in deny_keywords):
            # å°è¯•ä»æ–°çš„æè¿°ä¸­è¯†åˆ«æ„å›¾
            if len(user_response) > 10:  # å¦‚æœç”¨æˆ·æä¾›äº†è¾ƒé•¿çš„æè¿°
                # é‡æ–°åˆ†ææ„å›¾
                new_intent = await self.deepseek_intent_analysis(
                    user_response,
                    state.get_conversation_history(),
                    state
                )
                return False, new_intent
            return False, None

        # å¦‚æœæ—¢ä¸ç¡®è®¤ä¹Ÿä¸å¦è®¤ï¼Œå¯èƒ½æ˜¯ç”¨æˆ·ç›´æ¥è¯´æ˜äº†æ–°éœ€æ±‚
        if len(user_response) > 20:
            new_intent = await self.deepseek_intent_analysis(
                user_response,
                state.get_conversation_history(),
                state
            )
            return False, new_intent

        # é»˜è®¤è§†ä¸ºä¸ç¡®è®¤
        return False, None

    async def process_user_input_streaming(self, user_input: str, state: Optional[WorkflowState] = None) -> Tuple[
        WorkflowState, str]:
        """æµå¼å¤„ç†ç”¨æˆ·è¾“å…¥ - ğŸ”§ ä¿®å¤ï¼šæ‰€æœ‰æ„å›¾éƒ½æ”¯æŒæµå¼è¾“å‡º"""
        if state is None:
            state = WorkflowState()

        start_time = time.time()
        elapsed = 0.0
        assistant_response = ""
        visualization_data = None

        try:
            # å‘é€å¼€å§‹å¤„ç†ä¿¡å·
            await self.send_status("processing_start", {
                "message": "å¼€å§‹å¤„ç†æ‚¨çš„è¯·æ±‚...",
                "conversation_id": state.conversation_id
            })

            # æ­¥éª¤1: åˆå§‹åŒ–çŠ¶æ€
            state = await self.initialize_state_streaming(state, user_input)

            # ğŸ”§ å…³é”®ä¿®å¤ï¼šå…ˆæ£€æŸ¥æ˜¯å¦åœ¨ç­‰å¾…å‚æ•°æ¾„æ¸…å›å¤
            if state.metadata.get("awaiting_clarification", False):
                # å¦‚æœæ­£åœ¨ç­‰å¾…å‚æ•°æ¾„æ¸…ï¼Œç›´æ¥å¤„ç†æ¾„æ¸…å›å¤ï¼Œè·³è¿‡æ„å›¾åˆ†æ
                await self.send_status("thinking_step", {
                    "step": "å‚æ•°æ”¶é›†",
                    "message": "å¤„ç†æ‚¨çš„å‚æ•°å›å¤..."
                })

                state = await self.handle_parameter_clarification(state)

                if state.metadata.get("awaiting_clarification", False):
                    # ä»åœ¨ç­‰å¾…æ›´å¤šå‚æ•°
                    assistant_messages = [msg for msg in state.messages if msg.role == "assistant"]
                    assistant_response = assistant_messages[-1].content if assistant_messages else ""

                    await self.send_status("processing_complete", {
                        "message": "ç­‰å¾…å‚æ•°æ¾„æ¸…",
                        "clarification_pending": True
                    })

                    return state, assistant_response

                # å‚æ•°æ”¶é›†å®Œæˆï¼Œä½¿ç”¨ä¹‹å‰ä¿å­˜çš„æ„å›¾ç»§ç»­æµç¨‹
                intent = state.metadata.get("intent", "generate_plan")

            else:
                # ğŸ†• æ£€æŸ¥æ˜¯å¦åœ¨ç­‰å¾…æ„å›¾ç¡®è®¤
                if state.awaiting_intent_confirmation and state.pending_intent:
                    # å¤„ç†ç”¨æˆ·çš„ç¡®è®¤å›å¤
                    is_confirmed, new_intent = await self.handle_intent_confirmation(state, user_input)

                    if is_confirmed:
                        # ç”¨æˆ·ç¡®è®¤äº†æ„å›¾
                        state.metadata["intent"] = state.pending_intent
                        state.awaiting_intent_confirmation = False
                        state.intent_confirmed = True
                        intent = state.pending_intent
                        state.pending_intent = None

                        await self.send_status("thinking_step", {
                            "step": "æ„å›¾ç¡®è®¤",
                            "message": f"å·²ç¡®è®¤æ‚¨çš„æ„å›¾ï¼š{intent}"
                        })

                        # ç»§ç»­æ‰§è¡ŒåŸå®šæµç¨‹
                    elif new_intent:
                        # ç”¨æˆ·æä¾›äº†æ–°çš„æ„å›¾
                        state.metadata["intent"] = new_intent
                        state.pending_intent = new_intent
                        intent = new_intent

                        # ç”Ÿæˆæ–°çš„ç¡®è®¤æ¶ˆæ¯
                        confirmation_msg = await self.generate_intent_confirmation_message(intent, user_input)
                        state.add_message("assistant", confirmation_msg)

                        # æµå¼å‘é€ç¡®è®¤æ¶ˆæ¯
                        await self.content_sender.send_content_streaming(confirmation_msg, delay=0.05)

                        await self.send_status("processing_complete", {
                            "message": "ç­‰å¾…æ„å›¾ç¡®è®¤",
                            "awaiting_confirmation": True
                        })

                        return state, confirmation_msg
                    else:
                        # ç”¨æˆ·å¦è®¤ä½†æ²¡æœ‰æä¾›æ–°ä¿¡æ¯
                        clarify_msg = """æˆ‘ç†è§£æ‚¨çš„éœ€æ±‚å¯èƒ½ä¸åŒã€‚è¯·å‘Šè¯‰æˆ‘ï¼š

                æ‚¨å…·ä½“æƒ³è¦ä»€ä¹ˆå¸®åŠ©å‘¢ï¼Ÿæ¯”å¦‚ï¼š
                - ğŸ›°ï¸ è®¾è®¡å«æ˜Ÿç›‘æµ‹æ–¹æ¡ˆ
                - ğŸ“š äº†è§£è™šæ‹Ÿæ˜Ÿåº§çŸ¥è¯†
                - ğŸ”§ ä¼˜åŒ–ç°æœ‰æ–¹æ¡ˆ
                - ğŸ’¬ å…¶ä»–é—®é¢˜

                è¯·è¯¦ç»†æè¿°æ‚¨çš„éœ€æ±‚ã€‚"""

                        state.add_message("assistant", clarify_msg)
                        state.awaiting_intent_confirmation = False
                        state.pending_intent = None

                        await self.content_sender.send_content_streaming(clarify_msg, delay=0.08)

                        await self.send_status("processing_complete", {
                            "message": "è¯·æä¾›æ›´å¤šä¿¡æ¯"
                        })

                        return state, clarify_msg
                else:
                    # æ­¥éª¤2: åªæœ‰åœ¨éå‚æ•°æ¾„æ¸…çŠ¶æ€ä¸‹æ‰è¿›è¡Œæ„å›¾åˆ†æ
                    state = await self.analyze_user_input_streaming(state)
                    intent = state.metadata.get("intent", "unknown")

            if intent == "generate_plan" and not state.intent_confirmed:  # ä¿®æ”¹è¿™ä¸€è¡Œï¼Œä» ["generate_plan", "optimize_plan"] æ”¹ä¸ºåªæœ‰ "generate_plan"
                # ä¿å­˜å¾…ç¡®è®¤çš„æ„å›¾
                state.pending_intent = intent
                state.awaiting_intent_confirmation = True
                state.intent_confirmed = False

                # ç”Ÿæˆç¡®è®¤æ¶ˆæ¯
                confirmation_msg = await self.generate_intent_confirmation_message(intent, user_input)
                state.add_message("assistant", confirmation_msg)

                # æµå¼å‘é€ç¡®è®¤æ¶ˆæ¯
                await self.content_sender.send_content_streaming(confirmation_msg, delay=0.05)

                await self.send_status("processing_complete", {
                    "message": "ç­‰å¾…æ„å›¾ç¡®è®¤",
                    "awaiting_confirmation": True,
                    "pending_intent": intent
                })

                return state, confirmation_msg

            # ğŸ”§ å…³é”®æ”¹è¿›ï¼šæ‰€æœ‰æ„å›¾éƒ½ä½¿ç”¨æµå¼è¾“å‡º
            if intent == "greeting":
                # ğŸ†• æµå¼é—®å€™å›å¤
                response = await self.generate_greeting_response_streaming(state)
                state.add_message("assistant", response)
                assistant_response = response

            elif intent == "thanks":
                # ğŸ†• æµå¼æ„Ÿè°¢å›å¤
                response = await self.generate_thanks_response_streaming(state)
                state.add_message("assistant", response)
                assistant_response = response

            elif intent == "chat":
                # ğŸ†• æµå¼é—²èŠå›å¤
                response = await self.generate_chat_response_streaming(state)
                state.add_message("assistant", response)
                assistant_response = response

            elif intent == "generate_plan" and not state.metadata.get("clarification_completed", False):
                # ç”Ÿæˆæ–¹æ¡ˆéœ€è¦å‚æ•°æ¾„æ¸…
                state = await self.handle_parameter_clarification(state)

                if state.metadata.get("awaiting_clarification", False):
                    assistant_messages = [msg for msg in state.messages if msg.role == "assistant"]
                    assistant_response = assistant_messages[-1].content if assistant_messages else ""

                    await self.send_status("processing_complete", {
                        "message": "å‚æ•°æ¾„æ¸…ä¸­",
                        "clarification_pending": True,
                        "response": assistant_response
                    })

                    return state, assistant_response

            # å¤„ç†æ–¹æ¡ˆç”Ÿæˆæˆ–ä¼˜åŒ–
            elif intent in ["generate_plan", "optimize_plan"]:
                await self.send_status("thinking_step", {
                    "step": "æµç¨‹å‡†å¤‡",
                    "message": f"å‡†å¤‡å¤„ç†{intent}è¯·æ±‚..."
                })

                if intent == "generate_plan":
                    state = await self.retrieve_knowledge_streaming(state)
                    state = await self.generate_plan_streaming(state)

                elif intent == "optimize_plan":
                    if state.main_plan:
                        state = await self.optimize_plan_streaming(state)
                    else:
                        state = await self.retrieve_knowledge_streaming(state)
                        state = await self.generate_plan_streaming(state)

                # ç”Ÿæˆå“åº”ï¼ˆåŒ…å«å¯è§†åŒ–æ•°æ®å¤„ç†ï¼‰
                state = await self.generate_response_streaming(state)

            elif intent == "provide_info":
                # ğŸ†• æµå¼ä¿¡æ¯å›å¤
                info_response = await self.generate_info_response_streaming(state)
                state.add_message("assistant", info_response)
                assistant_response = info_response

            else:
                # ğŸ†• æµå¼é€šç”¨å›å¤
                general_response = await self.generate_general_response_streaming(state)
                state.add_message("assistant", general_response)
                assistant_response = general_response

            # ç»Ÿä¸€æå–åŠ©æ‰‹å“åº”å’Œå¯è§†åŒ–æ•°æ®
            if not assistant_response:
                for msg in reversed(state.messages):
                    if msg.role == "assistant":
                        assistant_response = msg.content
                        break

            state.intent_confirmed = False
            # è·å–å¯è§†åŒ–æ•°æ®
            visualization_data = state.metadata.get("visualization_data")

            elapsed = time.time() - start_time

        except Exception as e:
            logger.error(f"æµå¼å¤„ç†ç”¨æˆ·è¾“å…¥æ—¶å‡ºé”™: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())

            elapsed = time.time() - start_time
            # æä¾›æ›´å‹å¥½çš„é”™è¯¯ä¿¡æ¯ï¼Œä¸æš´éœ²æŠ€æœ¯ç»†èŠ‚
            error_type = type(e).__name__
            if "timeout" in str(e).lower() or "timeout" in error_type.lower():
                assistant_response = "æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶è¶…æ—¶äº†ã€‚è¯·ç¨åé‡è¯•ï¼Œæˆ–è€…å°è¯•ç®€åŒ–æ‚¨çš„éœ€æ±‚æè¿°ã€‚"
            elif "connection" in str(e).lower() or "network" in str(e).lower():
                assistant_response = "æŠ±æ­‰ï¼Œç½‘ç»œè¿æ¥å‡ºç°é—®é¢˜ã€‚è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥åé‡è¯•ã€‚"
            elif "api" in str(e).lower() or "deepseek" in str(e).lower():
                assistant_response = "æŠ±æ­‰ï¼ŒAIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ã€‚è¯·ç¨åé‡è¯•ï¼Œæˆ–è€…å°è¯•é‡æ–°æè¿°æ‚¨çš„éœ€æ±‚ã€‚"
            else:
                assistant_response = "æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶é‡åˆ°äº†é—®é¢˜ã€‚è¯·ç¨åé‡è¯•ï¼Œæˆ–è€…å°è¯•é‡æ–°æè¿°æ‚¨çš„éœ€æ±‚ã€‚"

            state.add_message("assistant", assistant_response)

            await self.send_status("error", {
                "message": "å¤„ç†è¯·æ±‚æ—¶å‡ºé”™",
                "response": assistant_response
            })

            return state, assistant_response

        # å‘é€å®Œæˆä¿¡å·
        try:
            logger.info(f"æµå¼å·¥ä½œæµå¤„ç†ç”¨æ—¶: {elapsed:.2f}ç§’")

            await self.send_status("thinking_step", {
                "step": "å¤„ç†å®Œæˆ",
                "message": f"å¤„ç†å®Œæˆï¼Œç”¨æ—¶ {elapsed:.1f} ç§’"
            })

            # ğŸ”§ ç®€åŒ–å®Œæˆæ•°æ®ï¼Œä¸å†åŒ…å«å¯è§†åŒ–æ•°æ®
            completion_data = {
                "message": "å¤„ç†å®Œæˆ",
                "extracted_satellites": getattr(state, 'extracted_satellites', []),
                "location": state.metadata.get("location")
            }

            await self.send_status("processing_complete", completion_data)

            return state, assistant_response

        except Exception as e:
            logger.error(f"å‘é€å®ŒæˆçŠ¶æ€æ—¶å‡ºé”™: {str(e)}")
            return state, assistant_response

    # ğŸ†• æ–°å¢ï¼šæµå¼é—®å€™å›å¤ç”Ÿæˆ
    async def generate_greeting_response_streaming(self, state: WorkflowState) -> str:
        """ç”Ÿæˆæµå¼é—®å€™å›å¤"""
        await self.send_status("thinking_step", {
            "step": "ç”Ÿæˆå›å¤",
            "message": "å‡†å¤‡å‹å¥½çš„é—®å€™å›å¤"
        })

        greetings = [
            "ä½ å¥½ï¼æˆ‘æ˜¯æ™ºæ…§è™šæ‹Ÿæ˜Ÿåº§åŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ã€‚æˆ‘å¯ä»¥å¸®åŠ©æ‚¨è®¾è®¡å®šåˆ¶åŒ–çš„è™šæ‹Ÿæ˜Ÿåº§æ–¹æ¡ˆï¼Œè¿›è¡Œå«æ˜Ÿç›‘æµ‹ä»»åŠ¡è§„åˆ’ã€‚æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ",
            "æ‚¨å¥½ï¼æ¬¢è¿ä½¿ç”¨æ™ºæ…§è™šæ‹Ÿæ˜Ÿåº§ç³»ç»Ÿã€‚æˆ‘å¯ä»¥æ ¹æ®æ‚¨çš„éœ€æ±‚è®¾è®¡æœ€é€‚åˆçš„å«æ˜Ÿè§‚æµ‹æ–¹æ¡ˆï¼Œæ— è®ºæ˜¯æ°´è´¨ç›‘æµ‹ã€å†œä¸šè§‚æµ‹è¿˜æ˜¯åŸå¸‚è§„åˆ’ï¼Œéƒ½èƒ½ä¸ºæ‚¨æä¾›ä¸“ä¸šçš„æ”¯æŒã€‚",
            "ä½ å¥½ï¼æˆ‘æ˜¯æ‚¨çš„è™šæ‹Ÿæ˜Ÿåº§è§„åˆ’ä¸“å®¶ã€‚è¯·å‘Šè¯‰æˆ‘æ‚¨çš„è§‚æµ‹éœ€æ±‚ï¼Œæˆ‘å°†ä¸ºæ‚¨é‡èº«å®šåˆ¶æœ€ä¼˜çš„å«æ˜Ÿç»„åˆæ–¹æ¡ˆã€‚"
        ]

        import random
        response = random.choice(greetings)

        # ğŸ”§ æµå¼å‘é€å›å¤
        await self.content_sender.send_content_streaming(response, delay=0.08)

        return response

    # ğŸ†• æ–°å¢ï¼šæµå¼æ„Ÿè°¢å›å¤ç”Ÿæˆ
    async def generate_thanks_response_streaming(self, state: WorkflowState) -> str:
        """ç”Ÿæˆæµå¼æ„Ÿè°¢å›å¤"""
        await self.send_status("thinking_step", {
            "step": "ç”Ÿæˆå›å¤",
            "message": "å‡†å¤‡ç¤¼è²Œçš„å›åº”"
        })

        responses = [
            "ä¸å®¢æ°”ï¼å¾ˆé«˜å…´èƒ½å¸®åŠ©åˆ°æ‚¨ã€‚å¦‚æœæ‚¨è¿˜æœ‰å…¶ä»–å…³äºè™šæ‹Ÿæ˜Ÿåº§çš„éœ€æ±‚ï¼Œéšæ—¶å‘Šè¯‰æˆ‘ã€‚",
            "æ‚¨å¤ªå®¢æ°”äº†ï¼ä¸ºæ‚¨æä¾›ä¸“ä¸šçš„è™šæ‹Ÿæ˜Ÿåº§æ–¹æ¡ˆæ˜¯æˆ‘çš„èŒè´£ã€‚æœŸå¾…ç»§ç»­ä¸ºæ‚¨æœåŠ¡ï¼",
            "å¾ˆé«˜å…´èƒ½å¤Ÿå¸®åŠ©æ‚¨ï¼å¦‚æœæ–¹æ¡ˆéœ€è¦è°ƒæ•´æˆ–æœ‰æ–°çš„ç›‘æµ‹éœ€æ±‚ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚"
        ]

        import random
        response = random.choice(responses)

        # ğŸ”§ æµå¼å‘é€å›å¤
        await self.content_sender.send_content_streaming(response, delay=0.08)

        return response

    # ğŸ†• ä¿®æ”¹ï¼šæµå¼é—²èŠå›å¤ç”Ÿæˆ
    async def generate_chat_response_streaming(self, state: WorkflowState) -> str:
        """ä½¿ç”¨DeepSeekç”Ÿæˆæµå¼é—²èŠå›å¤"""
        await self.send_status("thinking_step", {
            "step": "ç”Ÿæˆå›å¤",
            "message": "æ­£åœ¨æ€è€ƒåˆé€‚çš„å›å¤..."
        })

        # è·å–æœ€æ–°çš„ç”¨æˆ·æ¶ˆæ¯
        last_user_message = None
        for msg in reversed(state.messages):
            if msg.role == "user":
                last_user_message = msg.content
                break

        if not last_user_message:
            default_response = "æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰ç†è§£æ‚¨çš„æ„æ€ã€‚è¯·é—®æœ‰ä»€ä¹ˆå…³äºè™šæ‹Ÿæ˜Ÿåº§çš„éœ€æ±‚å—ï¼Ÿ"
            await self.content_sender.send_content_streaming(default_response, delay=0.08)
            return default_response

        # è·å–å¯¹è¯å†å²
        conversation_history = state.get_conversation_history(max_messages=10)

        # ğŸ”§ ä¿®æ”¹ï¼šä½¿ç”¨æµå¼APIè°ƒç”¨ï¼Œä¼ é€’å¯¹è¯å†å²
        response = await self._call_deepseek_streaming_for_chat(last_user_message, conversation_history)

        return response

    # ğŸ†• ä¿®æ”¹ï¼šæµå¼ä¿¡æ¯å›å¤ç”Ÿæˆ
    async def generate_info_response_streaming(self, state: WorkflowState) -> str:
        """æµå¼ç”Ÿæˆä¿¡æ¯æ€§å“åº” - æ”¯æŒæµå¼è¾“å‡º"""
        await self.send_status("thinking_step", {
            "step": "ä¿¡æ¯æŸ¥è¯¢",
            "message": "æ­£åœ¨å‡†å¤‡ç›¸å…³ä¿¡æ¯å›å¤"
        })

        # è·å–ç”¨æˆ·æœ€æ–°çš„æ¶ˆæ¯
        last_user_message = None
        for msg in reversed(state.messages):
            if msg.role == "user":
                last_user_message = msg.content
                break

        if not last_user_message:
            default_response = "æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰ç†è§£æ‚¨æƒ³äº†è§£ä»€ä¹ˆä¿¡æ¯ã€‚è¯·å‘Šè¯‰æˆ‘æ‚¨çš„å…·ä½“é—®é¢˜ã€‚"
            await self.content_sender.send_content_streaming(default_response, delay=0.08)
            return default_response

        # è·å–å¯¹è¯å†å²
        conversation_history = state.get_conversation_history(max_messages=20)

        # ğŸ”§ ä¿®æ”¹ï¼šä½¿ç”¨æµå¼APIè°ƒç”¨ï¼Œä¼ é€’å¯¹è¯å†å²
        response = await self._call_deepseek_streaming_for_info(last_user_message, conversation_history)

        return response

    # ğŸ†• ä¿®æ”¹ï¼šæµå¼é€šç”¨å›å¤ç”Ÿæˆ
    async def generate_general_response_streaming(self, state: WorkflowState) -> str:
        """æµå¼ç”Ÿæˆä¸€èˆ¬æ€§å“åº”"""
        await self.send_status("thinking_step", {
            "step": "å¯¹è¯å›å¤",
            "message": "ç”Ÿæˆå¼•å¯¼æ€§å›å¤"
        })

        if state.main_plan:
            response = "æ‚¨å¯¹å½“å‰çš„è™šæ‹Ÿæ˜Ÿåº§æ–¹æ¡ˆæœ‰ä»€ä¹ˆé—®é¢˜æˆ–éœ€è¦è¿›ä¸€æ­¥è°ƒæ•´å—ï¼Ÿæˆ‘å¯ä»¥æ ¹æ®æ‚¨çš„åé¦ˆå¯¹æ–¹æ¡ˆè¿›è¡Œä¼˜åŒ–ã€‚"
        else:
            response = """æˆ‘æ˜¯æ™ºæ…§è™šæ‹Ÿæ˜Ÿåº§åŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©æ‚¨è®¾è®¡å®šåˆ¶åŒ–çš„è™šæ‹Ÿæ˜Ÿåº§æ–¹æ¡ˆã€‚

## æˆ‘èƒ½ä¸ºæ‚¨åšä»€ä¹ˆï¼Ÿ

1. **æ–¹æ¡ˆè®¾è®¡**: æ ¹æ®æ‚¨çš„è§‚æµ‹éœ€æ±‚è®¾è®¡æœ€é€‚åˆçš„å«æ˜Ÿç»„åˆ
2. **æŠ€æœ¯å’¨è¯¢**: è§£ç­”è™šæ‹Ÿæ˜Ÿåº§ç›¸å…³çš„æŠ€æœ¯é—®é¢˜
3. **æ–¹æ¡ˆä¼˜åŒ–**: æ ¹æ®æ‚¨çš„åé¦ˆä¼˜åŒ–ç°æœ‰æ–¹æ¡ˆ

## å¼€å§‹ä½¿ç”¨

è¯·å‘Šè¯‰æˆ‘æ‚¨çš„å…·ä½“éœ€æ±‚ï¼Œæ¯”å¦‚ï¼š
- ç›‘æµ‹ç›®æ ‡å’ŒåŒºåŸŸ
- æ—¶é—´èŒƒå›´è¦æ±‚
- åˆ†è¾¨ç‡éœ€æ±‚
- åº”ç”¨åœºæ™¯

æˆ‘å°†ä¸ºæ‚¨é‡èº«å®šåˆ¶ä¸€ä¸ªè™šæ‹Ÿæ˜Ÿåº§æ–¹æ¡ˆï¼"""

        # ğŸ”§ æµå¼å‘é€å›å¤
        await self.content_sender.send_content_streaming(response, delay=0.06)

        return response

    # ğŸ†• æ–°å¢ï¼šæµå¼DeepSeekè°ƒç”¨ï¼ˆé—²èŠï¼‰
    async def _call_deepseek_streaming_for_chat(self, user_message: str, conversation_history: str = "") -> str:
        """ä½¿ç”¨DeepSeek APIè¿›è¡Œæµå¼é—²èŠå›å¤"""
        if not DEEPSEEK_API_KEY:
            default_response = "æˆ‘ç†è§£æ‚¨çš„æ„æ€ã€‚ä½œä¸ºè™šæ‹Ÿæ˜Ÿåº§åŠ©æ‰‹ï¼Œæˆ‘ä¸»è¦æ“…é•¿å¸®åŠ©æ‚¨è®¾è®¡å«æ˜Ÿç›‘æµ‹æ–¹æ¡ˆã€‚å¦‚æœæ‚¨æœ‰ç›¸å…³éœ€æ±‚ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼"
            await self.content_sender.send_content_streaming(default_response, delay=0.08)
            return default_response

        try:
            system_prompt = """ä½ æ˜¯æ™ºæ…§è™šæ‹Ÿæ˜Ÿåº§åŠ©æ‰‹ï¼Œä¸€ä¸ªä¸“ä¸šå‹å¥½çš„AIåŠ©æ‰‹ã€‚ä½ çš„ä¸»è¦èŒè´£æ˜¯å¸®åŠ©ç”¨æˆ·è®¾è®¡è™šæ‹Ÿæ˜Ÿåº§æ–¹æ¡ˆï¼Œä½†ä¹Ÿå¯ä»¥è¿›è¡Œå‹å¥½çš„å¯¹è¯ã€‚

è¯·æ³¨æ„ï¼š
1. ä¿æŒä¸“ä¸šä½†å‹å¥½çš„è¯­æ°”
2. å¦‚æœç”¨æˆ·çš„é—®é¢˜ä¸å«æ˜Ÿã€é¥æ„Ÿã€ç›‘æµ‹ç›¸å…³ï¼Œå¯ä»¥é€‚å½“å¼•å¯¼åˆ°ä½ çš„ä¸“ä¸šé¢†åŸŸ
3. å¦‚æœæ˜¯ä¸€èˆ¬æ€§å¯¹è¯ï¼Œç»™å‡ºç®€æ´å‹å¥½çš„å›å¤
4. é€‚æ—¶æé†’ç”¨æˆ·ä½ å¯ä»¥å¸®åŠ©è®¾è®¡è™šæ‹Ÿæ˜Ÿåº§æ–¹æ¡ˆ
5. è®°ä½ä¹‹å‰çš„å¯¹è¯å†…å®¹ï¼Œä¿æŒå¯¹è¯çš„è¿è´¯æ€§"""

            # ğŸ”§ ä½¿ç”¨æµå¼APIè°ƒç”¨ï¼Œä¼ é€’å¯¹è¯å†å²
            response = await self._stream_deepseek_response_with_history(system_prompt, user_message,
                                                                         conversation_history)
            return response

        except Exception as e:
            logger.error(f"ç”Ÿæˆé—²èŠå›å¤æ—¶å‡ºé”™: {str(e)}")
            default_response = "æˆ‘ç†è§£æ‚¨çš„æ„æ€ã€‚ä½œä¸ºè™šæ‹Ÿæ˜Ÿåº§åŠ©æ‰‹ï¼Œæˆ‘ä¸»è¦æ“…é•¿å¸®åŠ©æ‚¨è®¾è®¡å«æ˜Ÿç›‘æµ‹æ–¹æ¡ˆã€‚å¦‚æœæ‚¨æœ‰ç›¸å…³éœ€æ±‚ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼"
            await self.content_sender.send_content_streaming(default_response, delay=0.08)
            return default_response

    # ğŸ†• æ–°å¢ï¼šæµå¼DeepSeekè°ƒç”¨ï¼ˆä¿¡æ¯æŸ¥è¯¢ï¼‰
    async def _call_deepseek_streaming_for_info(self, user_message: str, conversation_history: str = "") -> str:
        """ä½¿ç”¨DeepSeek APIè¿›è¡Œæµå¼ä¿¡æ¯å›å¤"""
        if not DEEPSEEK_API_KEY:
            default_response = """è™šæ‹Ÿæ˜Ÿåº§æ˜¯æŒ‡å°†åˆ†å±ä¸åŒç»„ç»‡çš„å¤šé¢—å«æ˜Ÿèµ„æºé€šè¿‡è½¯ä»¶å’Œç½‘ç»œæŠ€æœ¯é›†ä¸­ç®¡ç†å’Œè°ƒåº¦ï¼Œå®ç°èµ„æºå…±äº«ã€ä»»åŠ¡ååŒå’Œæ•°æ®èåˆçš„åˆ›æ–°é¥æ„Ÿæ•°æ®è·å–æ¨¡å¼ã€‚

## æ ¸å¿ƒç‰¹ç‚¹

ä¸ä¼ ç»Ÿçš„ç‰©ç†æ˜Ÿåº§ï¼ˆåŒä¸€ç»„ç»‡è¿è¥çš„å«æ˜Ÿç¾¤ï¼‰ä¸åŒï¼Œè™šæ‹Ÿæ˜Ÿåº§çªç ´äº†ç»„ç»‡è¾¹ç•Œï¼Œèƒ½å¤Ÿæ›´çµæ´»åœ°æ•´åˆå…¨çƒå«æ˜Ÿèµ„æºï¼Œä¼˜åŒ–é¥æ„Ÿæ•°æ®è·å–æ•ˆç‡ã€‚

## ä¸»è¦ä¼˜åŠ¿

1. **èµ„æºæ•´åˆ**: ç»Ÿä¸€è°ƒåº¦å¤šä¸ªç»„ç»‡çš„å«æ˜Ÿèµ„æº
2. **æˆæœ¬æ•ˆç›Š**: é™ä½å•ä¸€ç»„ç»‡çš„å«æ˜Ÿéƒ¨ç½²æˆæœ¬
3. **è¦†ç›–å¢å¼º**: æé«˜å…¨çƒè§‚æµ‹è¦†ç›–èƒ½åŠ›
4. **æ•°æ®èåˆ**: å®ç°å¤šæºæ•°æ®çš„ååŒå¤„ç†

## åº”ç”¨åœºæ™¯

è™šæ‹Ÿæ˜Ÿåº§åŠ©æ‰‹å¯ä»¥å¸®åŠ©æ‚¨è®¾è®¡é’ˆå¯¹ç‰¹å®šéœ€æ±‚çš„æœ€ä¼˜å«æ˜Ÿç»„åˆæ–¹æ¡ˆï¼ŒåŒ…æ‹¬ç¯å¢ƒç›‘æµ‹ã€ç¾å®³é¢„è­¦ã€å†œä¸šé¥æ„Ÿç­‰å¤šä¸ªé¢†åŸŸã€‚

è¯·å‘Šè¯‰æˆ‘æ‚¨çš„å…·ä½“éœ€æ±‚ï¼Œä¾‹å¦‚ç›‘æµ‹ç›®æ ‡ã€æ—¶é—´è¦æ±‚ã€åˆ†è¾¨ç‡éœ€æ±‚ç­‰ï¼Œæˆ‘å°†ä¸ºæ‚¨è®¾è®¡ä¸€ä¸ªå®šåˆ¶åŒ–çš„è™šæ‹Ÿæ˜Ÿåº§æ–¹æ¡ˆã€‚"""
            await self.content_sender.send_content_streaming(default_response, delay=0.05)
            return default_response

        try:
            system_prompt = """ä½ æ˜¯æ™ºæ…§è™šæ‹Ÿæ˜Ÿåº§åŠ©æ‰‹ï¼Œä¸€ä¸ªçŸ¥è¯†æ¸Šåšçš„AIåŠ©æ‰‹ã€‚ä½ çš„ä¸»è¦èŒè´£æ˜¯å¸®åŠ©ç”¨æˆ·è®¾è®¡è™šæ‹Ÿæ˜Ÿåº§æ–¹æ¡ˆï¼Œä½†ä½ ä¹Ÿå…·å¤‡å¹¿æ³›çš„çŸ¥è¯†ï¼Œå¯ä»¥å›ç­”å„ç§é—®é¢˜ã€‚

å›ç­”åŸåˆ™ï¼š
1. å‡†ç¡®ã€ä¸“ä¸šåœ°å›ç­”ç”¨æˆ·çš„é—®é¢˜
2. ä½¿ç”¨ç»“æ„åŒ–çš„æ–¹å¼ç»„ç»‡ä¿¡æ¯ï¼ˆå¦‚ä½¿ç”¨æ ‡é¢˜ã€åˆ—è¡¨ç­‰ï¼‰
3. å¦‚æœé—®é¢˜ä¸å«æ˜Ÿã€é¥æ„Ÿã€åœ°çƒè§‚æµ‹ç›¸å…³ï¼Œå¯ä»¥é€‚å½“å¼•å…¥ä½ çš„ä¸“ä¸šé¢†åŸŸ
4. å¦‚æœé—®é¢˜å®Œå…¨æ— å…³ï¼Œä¹Ÿè¦ç»™å‡ºå‡†ç¡®çš„å›ç­”ï¼Œä½†åœ¨æœ€åå¯ä»¥æ¸©å’Œåœ°æé†’ç”¨æˆ·ä½ çš„ä¸»è¦åŠŸèƒ½
5. å›ç­”è¦è¯¦ç»†ä½†ä¸å†—é•¿ï¼Œæ§åˆ¶åœ¨800å­—ä»¥å†…"""

            # ğŸ”§ ä½¿ç”¨æµå¼APIè°ƒç”¨ï¼Œä¼ é€’å¯¹è¯å†å²
            response = await self._stream_deepseek_response_with_history(system_prompt, user_message,
                                                                         conversation_history)
            return response

        except Exception as e:
            logger.error(f"ç”Ÿæˆä¿¡æ¯å›å¤æ—¶å‡ºé”™: {str(e)}")
            default_response = "æŠ±æ­‰ï¼Œè·å–ä¿¡æ¯æ—¶å‡ºç°é—®é¢˜ã€‚ä½œä¸ºè™šæ‹Ÿæ˜Ÿåº§åŠ©æ‰‹ï¼Œæˆ‘ä¸»è¦ä¸“é•¿äºè®¾è®¡å«æ˜Ÿç›‘æµ‹æ–¹æ¡ˆã€‚è¯·é—®æ‚¨æœ‰ç›¸å…³çš„è§‚æµ‹éœ€æ±‚å—ï¼Ÿ"
            await self.content_sender.send_content_streaming(default_response, delay=0.08)
            return default_response

    # ğŸ†• æ–°å¢ï¼šé€šç”¨çš„æµå¼DeepSeek APIè°ƒç”¨
    async def _stream_deepseek_response(self, system_prompt: str, user_message: str) -> str:
        """é€šç”¨çš„æµå¼DeepSeek APIè°ƒç”¨æ–¹æ³•"""
        return await self._stream_deepseek_response_with_history(system_prompt, user_message, "")

    # ğŸ†• æ–°å¢ï¼šå¸¦å¯¹è¯å†å²çš„æµå¼DeepSeek APIè°ƒç”¨
    async def _stream_deepseek_response_with_history(self, system_prompt: str, user_message: str,
                                                     conversation_history: str = "") -> str:
        """å¸¦å¯¹è¯å†å²çš„æµå¼DeepSeek APIè°ƒç”¨æ–¹æ³•"""
        import aiohttp

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {DEEPSEEK_API_KEY}"
        }

        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = [{"role": "system", "content": system_prompt}]

        # æ™ºèƒ½å¤„ç†å¯¹è¯å†å²
        if conversation_history and conversation_history.strip():
            # å°†å¯¹è¯å†å²è½¬æ¢ä¸ºæ¶ˆæ¯æ ¼å¼
            history_lines = conversation_history.strip().split('\n')
            history_messages = []

            for line in history_lines:
                if line.startswith('user: '):
                    history_messages.append({"role": "user", "content": line[6:]})
                elif line.startswith('assistant: '):
                    history_messages.append({"role": "assistant", "content": line[11:]})

            # æ™ºèƒ½æˆªæ–­ï¼šä¿ç•™æœ€è¿‘çš„å¯¹è¯ï¼Œä½†ç¡®ä¿ä¸è¶…è¿‡åˆç†é•¿åº¦
            max_history_messages = 20  # æœ€å¤šä¿ç•™20è½®å¯¹è¯
            if len(history_messages) > max_history_messages:
                # ä¿ç•™æœ€è¿‘çš„å¯¹è¯
                history_messages = history_messages[-max_history_messages:]
                logger.info(f"å¯¹è¯å†å²è¿‡é•¿ï¼Œæˆªæ–­ä¸ºæœ€è¿‘{max_history_messages}è½®å¯¹è¯")

            messages.extend(history_messages)

        # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
        messages.append({"role": "user", "content": user_message})

        data = {
            "model": "deepseek-chat",
            "messages": messages,
            "temperature": 0.7,
            "max_tokens": 800,
            "stream": True  # ğŸ”§ å¯ç”¨æµå¼å“åº”
        }

        full_response = ""

        try:
            timeout = aiohttp.ClientTimeout(total=60, connect=10)

            async with aiohttp.ClientSession(timeout=timeout) as session:
                async with session.post(
                        "https://api.deepseek.com/v1/chat/completions",
                        headers=headers,
                        json=data
                ) as response:

                    if response.status != 200:
                        error_text = await response.text()
                        logger.error(f"DeepSeek APIè¯·æ±‚å¤±è´¥: {response.status}, {error_text}")
                        raise Exception(f"APIè¯·æ±‚å¤±è´¥: {response.status}")

                    # ğŸ”§ å¤„ç†æµå¼å“åº”
                    async for chunk in response.content.iter_chunked(1024):
                        try:
                            chunk_text = chunk.decode('utf-8', errors='ignore')
                            lines = chunk_text.strip().split('\n')

                            for line in lines:
                                line = line.strip()
                                if line.startswith('data: '):
                                    data_content = line[6:]

                                    if data_content == '[DONE]':
                                        break

                                    if not data_content.strip():
                                        continue

                                    try:
                                        json_data = json.loads(data_content)
                                        if 'choices' in json_data and len(json_data['choices']) > 0:
                                            delta = json_data['choices'][0].get('delta', {})
                                            if 'content' in delta:
                                                content_chunk = delta['content']
                                                full_response += content_chunk

                                                # ğŸ”§ å®æ—¶å‘é€å†…å®¹å—
                                                if self.websocket_callback:
                                                    await self.websocket_callback({
                                                        "type": "response_chunk",
                                                        "content": content_chunk,
                                                        "accumulated_content": full_response,
                                                        "chunk_type": "ai_response"
                                                    })

                                                # é€‚å½“å»¶è¿Ÿä»¥æ§åˆ¶å‘é€é€Ÿåº¦
                                                await asyncio.sleep(0.02)

                                    except json.JSONDecodeError:
                                        continue

                        except Exception as e:
                            logger.debug(f"å¤„ç†æµå¼æ•°æ®å—æ—¶å‡ºé”™: {e}")
                            continue

            return full_response.strip() if full_response else "æŠ±æ­‰ï¼Œæœªèƒ½ç”Ÿæˆæœ‰æ•ˆå›å¤ã€‚"

        except Exception as e:
            logger.error(f"æµå¼APIè°ƒç”¨å¤±è´¥: {str(e)}")
            raise

    async def initialize_state_streaming(self, state: WorkflowState, user_input: str) -> WorkflowState:
        """æµå¼åˆå§‹åŒ–çŠ¶æ€"""
        self.reset_session()

        message = state.add_message("user", user_input if isinstance(user_input, str) else str(user_input))
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ¾„æ¸…å›å¤ï¼ˆé€šè¿‡metadataè·Ÿè¸ªï¼‰
        if state.metadata.get("awaiting_clarification", False):
            state.metadata["is_clarification_response"] = True

        state.add_thinking_step("åˆå§‹åŒ–", "å¼€å§‹å¤„ç†ç”¨æˆ·è¾“å…¥")
        state.current_stage = "analyze_input"

        await self.send_status("thinking_step", {
            "step": "åˆå§‹åŒ–",
            "message": "å¼€å§‹å¤„ç†ç”¨æˆ·è¾“å…¥",
            "stage": "initialize"
        })

        return state

    async def deepseek_intent_analysis(self, user_message: str, conversation_history: str,
                                       state: WorkflowState) -> str:
        """ä½¿ç”¨DeepSeekè¿›è¡Œæ™ºèƒ½æ„å›¾åˆ†æ - å¢å¼ºç‰ˆæœ¬"""
        if not DEEPSEEK_API_KEY:
            logger.warning("DeepSeek APIå¯†é’¥æœªè®¾ç½®ï¼Œä½¿ç”¨é»˜è®¤æ„å›¾åˆ†æ")
            return "chat"  # é»˜è®¤ä¸ºé—²èŠ

        system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ„å›¾åˆ†æä¸“å®¶ï¼Œéœ€è¦å‡†ç¡®è¯†åˆ«ç”¨æˆ·åœ¨è™šæ‹Ÿæ˜Ÿåº§åŠ©æ‰‹å¯¹è¯ä¸­çš„æ„å›¾ã€‚

    è¯·åˆ†æç”¨æˆ·çš„è¾“å…¥ï¼Œå¹¶è¿”å›ä»¥ä¸‹æ„å›¾ä¹‹ä¸€ï¼š
    1. "greeting" - ç”¨æˆ·åœ¨æ‰“æ‹›å‘¼æˆ–é—®å€™ï¼ˆå¦‚ï¼šä½ å¥½ã€æ‚¨å¥½ã€hiã€helloç­‰ï¼‰
    2. "thanks" - ç”¨æˆ·åœ¨è¡¨ç¤ºæ„Ÿè°¢ï¼ˆå¦‚ï¼šè°¢è°¢ã€æ„Ÿè°¢ã€å¤šè°¢ç­‰ï¼‰
    3. "generate_plan" - ç”¨æˆ·æƒ³è¦ç”Ÿæˆè™šæ‹Ÿæ˜Ÿåº§æ–¹æ¡ˆï¼ŒåŒ…å«ä»¥ä¸‹æƒ…å†µï¼š
       - æ˜ç¡®æåˆ°ç›‘æµ‹ã€è§‚æµ‹ã€è®¾è®¡ã€è§„åˆ’ç­‰éœ€æ±‚
       - æè¿°å…·ä½“çš„ç›‘æµ‹ç›®æ ‡ï¼ˆå¦‚æ°´è´¨ã€å†œä¸šã€åŸå¸‚ç­‰ï¼‰
       - æåˆ°åœ°ç†ä½ç½®å’Œç›‘æµ‹éœ€æ±‚
       - è¯¢é—®å¦‚ä½•è®¾è®¡å«æ˜Ÿæ–¹æ¡ˆ
    4. "optimize_plan" - ç”¨æˆ·æƒ³è¦ä¼˜åŒ–æˆ–ä¿®æ”¹ç°æœ‰æ–¹æ¡ˆï¼ˆå¦‚ï¼šä¼˜åŒ–ã€æ”¹è¿›ã€è°ƒæ•´ã€ä¿®æ”¹ç­‰ï¼‰
    5. "provide_info" - ç”¨æˆ·åœ¨è¯¢é—®ä¿¡æ¯æˆ–çŸ¥è¯†ï¼ŒåŒ…æ‹¬ï¼š
       - è¯¢é—®"ä»€ä¹ˆæ˜¯"ã€"ä»‹ç»ä¸€ä¸‹"ã€"è§£é‡Š"ã€"è¯´æ˜"ç­‰
       - è¯¢é—®å…³äºä»»ä½•äº‹ç‰©çš„åŸºç¡€çŸ¥è¯†æˆ–ä¿¡æ¯
       - ä¸æ¶‰åŠå…·ä½“ç›‘æµ‹éœ€æ±‚çš„ä¸€èˆ¬æ€§è¯¢é—®
    6. "chat" - ä¸€èˆ¬é—²èŠæˆ–å…¶ä»–ä¸æ˜ç¡®çš„æ„å›¾

    é‡è¦åˆ¤æ–­åŸåˆ™ï¼š
    - å½“ç”¨æˆ·ä½¿ç”¨"ä»‹ç»"ã€"ä»€ä¹ˆæ˜¯"ã€"è§£é‡Š"ç­‰è¯æ±‡æ—¶ï¼Œä¼˜å…ˆåˆ¤æ–­ä¸º"provide_info"
    - åªæœ‰å½“ç”¨æˆ·æ˜ç¡®è¡¨è¾¾äº†ç›‘æµ‹ã€è§‚æµ‹ã€è®¾è®¡ç­‰éœ€æ±‚æ—¶æ‰è¿”å›"generate_plan"
    - å¦‚æœç”¨æˆ·åªæ˜¯ç®€å•é—®å€™æˆ–é—²èŠï¼Œè¿”å›å¯¹åº”çš„æ„å›¾ï¼Œä¸è¦é»˜è®¤ä¸º"generate_plan"
    - ä»”ç»†åŒºåˆ†ç”¨æˆ·æ˜¯åœ¨è¯¢é—®ä¿¡æ¯è¿˜æ˜¯è¦æ±‚è®¾è®¡æ–¹æ¡ˆ

    è¯·åªè¿”å›æ„å›¾æ ‡ç­¾ï¼Œä¸è¦æœ‰å…¶ä»–å†…å®¹ã€‚"""

        prompt = f"""ç”¨æˆ·è¾“å…¥: {user_message}

    å¯¹è¯å†å²:
    {conversation_history}

    è¯·ä»”ç»†åˆ†æç”¨æˆ·æ„å›¾å¹¶è¿”å›å¯¹åº”çš„æ ‡ç­¾ã€‚"""

        try:
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {DEEPSEEK_API_KEY}"
            }

            data = {
                "model": "deepseek-chat",
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0.2,
                "max_tokens": 50
            }

            response = requests.post(
                "https://api.deepseek.com/v1/chat/completions",
                headers=headers,
                json=data,
                timeout=10
            )

            if response.status_code == 200:
                result = response.json()
                intent = result["choices"][0]["message"]["content"].strip().lower()

                # éªŒè¯è¿”å›çš„æ„å›¾æ˜¯å¦æœ‰æ•ˆ
                valid_intents = ["greeting", "thanks", "generate_plan", "optimize_plan", "provide_info", "chat"]
                if intent in valid_intents:
                    logger.info(f"âœ… DeepSeekæ„å›¾åˆ†æç»“æœ: {intent}")
                    return intent
                else:
                    logger.warning(f"âŒ DeepSeekè¿”å›äº†æ— æ•ˆçš„æ„å›¾: {intent}ï¼Œä½¿ç”¨é»˜è®¤æ„å›¾")
                    return "chat"
            else:
                logger.error(f"âŒ DeepSeek APIè°ƒç”¨å¤±è´¥: {response.status_code}")
                return "chat"

        except Exception as e:
            logger.error(f"âŒ DeepSeekæ„å›¾åˆ†æå‡ºé”™: {str(e)}")
            return "chat"

    async def analyze_user_input_streaming(self, state: WorkflowState) -> WorkflowState:
        """æµå¼æ„å›¾åˆ†æ - ä¿®å¤ï¼šæ£€æµ‹æ–°æ–¹æ¡ˆè¯·æ±‚æ—¶é‡ç½®æ¾„æ¸…çŠ¶æ€"""
        conversation_history = state.get_conversation_history(max_messages=30)

        last_user_message = None
        for msg in reversed(state.messages):
            if msg.role == "user":
                last_user_message = msg.content
                break

        if not last_user_message:
            state.add_thinking_step("æ„å›¾åˆ†æ", "æœªæ‰¾åˆ°ç”¨æˆ·æ¶ˆæ¯")
            state.metadata["intent"] = "unknown"
            return state

        await self.send_status("thinking_step", {
            "step": "æ„å›¾åˆ†æ",
            "message": f"æ­£åœ¨åˆ†æç”¨æˆ·æ„å›¾: '{last_user_message[:50]}...'",
            "stage": "analyze_intent"
        })

        # ä½¿ç”¨DeepSeekè¿›è¡Œæ„å›¾åˆ†æ
        logger.info("ç›´æ¥ä½¿ç”¨DeepSeekè¿›è¡Œæ™ºèƒ½æ„å›¾åˆ†æ")
        intent = await self.deepseek_intent_analysis(last_user_message, conversation_history, state)

        # ğŸ”§ å…³é”®ä¿®å¤ï¼šæ£€æµ‹æ˜¯å¦æ˜¯æ–°çš„æ–¹æ¡ˆç”Ÿæˆè¯·æ±‚
        if intent == "generate_plan":
            # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰æ–¹æ¡ˆå­˜åœ¨
            has_existing_plan = state.main_plan is not None

            # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°çš„ç›‘æµ‹éœ€æ±‚ï¼ˆè€Œä¸æ˜¯å¯¹ç°æœ‰æ–¹æ¡ˆçš„è®¨è®ºï¼‰
            # new_plan_keywords = ['è§„åˆ’', 'è®¾è®¡']
            # is_new_request = any(keyword in last_user_message for keyword in new_plan_keywords)
            print('zzzzzzzzzzzzzzzzzz', last_user_message)
            # å¦‚æœå·²æœ‰æ–¹æ¡ˆä¸”æ˜¯æ–°è¯·æ±‚ï¼Œé‡ç½®æ¾„æ¸…çŠ¶æ€å¹¶æ ‡è®°æ–°æ–¹æ¡ˆèµ·å§‹
            if has_existing_plan:
                logger.info("ğŸ”„ æ£€æµ‹åˆ°æ–°çš„æ–¹æ¡ˆç”Ÿæˆè¯·æ±‚ï¼Œé‡ç½®æ¾„æ¸…çŠ¶æ€")
                state.metadata["clarification_completed"] = False
                state.metadata["clarification_skipped"] = False
                state.metadata["extracted_parameters"] = {}
                state.metadata["awaiting_clarification"] = False
                state.metadata["pending_questions"] = []

                # é‡ç½®å‚æ•°æ”¶é›†é˜¶æ®µ
                state.parameter_collection_stage = "not_started"
                state.parameter_collection_history = []
                state.stage_retry_count = {}

                # ğŸ†• å…³é”®ï¼šæ ‡è®°æ–°æ–¹æ¡ˆè¯·æ±‚çš„èµ·å§‹ä½ç½®
                state.mark_new_plan_request()

                # æ·»åŠ æ€è€ƒæ­¥éª¤
                state.add_thinking_step("æ–°æ–¹æ¡ˆæ£€æµ‹", "æ£€æµ‹åˆ°æ–°çš„æ–¹æ¡ˆéœ€æ±‚ï¼Œå°†é‡æ–°æ”¶é›†å‚æ•°")

            # ğŸ†• å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡æ–¹æ¡ˆè¯·æ±‚ï¼Œä¹Ÿè¦æ ‡è®°
            # elif not has_existing_plan:
            #     state.mark_new_plan_request()
            #     logger.info("ğŸ”– æ ‡è®°ç¬¬ä¸€æ¬¡æ–¹æ¡ˆè¯·æ±‚")

            # è®¾ç½®éœ€è¦æ¾„æ¸…æ ‡å¿—
            is_clarification_response = state.metadata.get("is_clarification_response", False)
            if not is_clarification_response and not state.metadata.get("clarification_completed", False):
                state.metadata["needs_clarification"] = True
                logger.info("æ£€æµ‹åˆ°æ–¹æ¡ˆç”Ÿæˆéœ€æ±‚ï¼Œéœ€è¦å‚æ•°æ¾„æ¸…")
            else:
                logger.info("å·²å®Œæˆå‚æ•°æ¾„æ¸…æˆ–æ­£åœ¨å¤„ç†æ¾„æ¸…å›å¤ï¼Œè·³è¿‡æ¾„æ¸…æ­¥éª¤")

        state.metadata["intent"] = intent
        state.add_thinking_step("æ„å›¾è¯†åˆ«", f"è¯†åˆ«æ„å›¾: {intent}")

        await self.send_status("thinking_step", {
            "step": "æ„å›¾è¯†åˆ«",
            "message": f"AIæ™ºèƒ½è¯†åˆ«æ„å›¾: {intent}",
            "stage": "analyze_intent"
        })

        return state

    async def retrieve_knowledge_streaming(self, state: WorkflowState) -> WorkflowState:
        """æµå¼çŸ¥è¯†æ£€ç´¢ - å¢å¼ºç‰ˆï¼šåŒ…å«ç½‘ç»œæœç´¢"""
        await self.send_status("thinking_step", {
            "step": "çŸ¥è¯†æ£€ç´¢",
            "message": "æ­£åœ¨åˆ†æç”¨æˆ·éœ€æ±‚..."
        })

        await asyncio.sleep(0.3)

        # æ­¥éª¤1ï¼šçŸ¥è¯†åº“æ£€ç´¢
        state = retrieve_knowledge_for_workflow(state)
        knowledge_count = len(state.retrieved_knowledge)

        await self.send_status("thinking_step", {
            "step": "çŸ¥è¯†åº“æ£€ç´¢",
            "message": f"ä»çŸ¥è¯†åº“æ£€ç´¢åˆ° {knowledge_count} æ¡ç›¸å…³ä¿¡æ¯"
        })

        # æ­¥éª¤2ï¼šç½‘ç»œæœç´¢å¢å¼º
        try:
            from backend.src.tools.web_search_tools import WebSearchTool, integrate_search_with_knowledge

            search_tool = WebSearchTool()
            if search_tool.default_provider:
                await self.send_status("thinking_step", {
                    "step": "ç½‘ç»œæœç´¢",
                    "message": "æ­£åœ¨æœç´¢æœ€æ–°å«æ˜Ÿä¿¡æ¯..."
                })

                # æå–å…³é”®ä¿¡æ¯è¿›è¡Œæœç´¢
                user_messages = [msg.content for msg in state.messages if msg.role == "user"]
                search_query = user_messages[-1] if user_messages else ""

                # æ‰§è¡Œç½‘ç»œæœç´¢
                search_results = await search_tool.search(
                    search_query,
                    max_results=5,
                    search_type="satellite"
                )

                if search_results:
                    # å¦‚æœæœ‰å«æ˜Ÿä¿¡æ¯ï¼Œæœç´¢å…·ä½“å«æ˜Ÿ
                    if hasattr(state, 'extracted_satellites') and state.extracted_satellites:
                        satellite_info = await search_tool.search_satellite_info(
                            state.extracted_satellites[:3]  # é™åˆ¶æœç´¢å‰3ä¸ªå«æ˜Ÿ
                        )

                        # å°†å«æ˜Ÿä¿¡æ¯æ·»åŠ åˆ°æœç´¢ç»“æœ
                        for satellite, info_list in satellite_info.items():
                            state.metadata[f"satellite_info_{satellite}"] = info_list

                    # æ•´åˆçŸ¥è¯†åº“å’Œæœç´¢ç»“æœ
                    integrated_knowledge = integrate_search_with_knowledge(
                        state.retrieved_knowledge,
                        search_results
                    )

                    # å°†æ•´åˆåçš„çŸ¥è¯†æ·»åŠ åˆ°çŠ¶æ€
                    state.retrieved_knowledge.append({
                        "content": integrated_knowledge,
                        "source": "integrated_search",
                        "score": 0.9
                    })

                    await self.send_status("thinking_step", {
                        "step": "ç½‘ç»œæœç´¢å®Œæˆ",
                        "message": f"è¡¥å……äº† {len(search_results)} æ¡ç½‘ç»œä¿¡æ¯"
                    })
                else:
                    await self.send_status("thinking_step", {
                        "step": "ç½‘ç»œæœç´¢",
                        "message": "ç½‘ç»œæœç´¢æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯"
                    })
            else:
                logger.info("ç½‘ç»œæœç´¢åŠŸèƒ½æœªé…ç½®ï¼Œè·³è¿‡")

        except Exception as e:
            logger.error(f"ç½‘ç»œæœç´¢å¤±è´¥: {str(e)}")
            await self.send_status("thinking_step", {
                "step": "ç½‘ç»œæœç´¢",
                "message": "ç½‘ç»œæœç´¢é‡åˆ°é—®é¢˜ï¼Œä½¿ç”¨çŸ¥è¯†åº“ä¿¡æ¯"
            })

        await self.send_status("thinking_step", {
            "step": "çŸ¥è¯†æ£€ç´¢å®Œæˆ",
            "message": f"å…±è·å– {len(state.retrieved_knowledge)} æ¡å‚è€ƒä¿¡æ¯"
        })

        state.current_stage = "generate_plan"
        return state

    async def generate_plan_streaming(self, state: WorkflowState) -> WorkflowState:
        """çœŸæ­£çš„æµå¼æ–¹æ¡ˆç”Ÿæˆ"""
        await self.send_status("thinking_step", {
            "step": "æ–¹æ¡ˆç”Ÿæˆ",
            "message": "å¼€å§‹è°ƒç”¨AIæ¨¡å‹æµå¼ç”Ÿæˆæ–¹æ¡ˆ..."
        })

        async def plan_callback(data):
            if data["type"] == "thinking_step":
                await self.send_status("thinking_step", {
                    "step": data["step"],
                    "message": data["message"]
                })
            elif data["type"] == "plan_content_chunk":
                await self.send_status("response_chunk", {
                    "content": data["content"],
                    "accumulated_content": data["accumulated_content"],
                    "chunk_type": "plan_generation"
                })

        state = await generate_constellation_plan_streaming(state, plan_callback)

        await self.send_status("thinking_step", {
            "step": "æ–¹æ¡ˆç”Ÿæˆå®Œæˆ",
            "message": "è™šæ‹Ÿæ˜Ÿåº§æ–¹æ¡ˆå·²æµå¼ç”Ÿæˆå®Œæˆ"
        })

        state.current_stage = "respond"
        return state

    async def optimize_plan_streaming(self, state: WorkflowState) -> WorkflowState:
        """çœŸæ­£çš„æµå¼æ–¹æ¡ˆä¼˜åŒ–"""
        last_user_message = None
        for msg in reversed(state.messages):
            if msg.role == "user":
                last_user_message = msg.content
                break

        if not last_user_message:
            state.add_thinking_step("ä¼˜åŒ–é”™è¯¯", "æœªæ‰¾åˆ°ç”¨æˆ·åé¦ˆ")
            return state

        await self.send_status("thinking_step", {
            "step": "æ–¹æ¡ˆä¼˜åŒ–",
            "message": f"å¼€å§‹æ ¹æ®åé¦ˆä¼˜åŒ–æ–¹æ¡ˆ: {last_user_message[:30]}..."
        })

        async def optimize_callback(data):
            if data["type"] == "thinking_step":
                await self.send_status("thinking_step", {
                    "step": data["step"],
                    "message": data["message"]
                })
            elif data["type"] == "plan_content_chunk":
                await self.send_status("response_chunk", {
                    "content": data["content"],
                    "accumulated_content": data["accumulated_content"],
                    "chunk_type": "plan_optimization"
                })

        state = await optimize_constellation_plan_streaming(state, last_user_message, optimize_callback)

        await self.send_status("thinking_step", {
            "step": "æ–¹æ¡ˆä¼˜åŒ–å®Œæˆ",
            "message": "æ–¹æ¡ˆå·²æ ¹æ®æ‚¨çš„åé¦ˆæµå¼ä¼˜åŒ–å®Œæˆ"
        })

        state.current_stage = "respond"
        return state

    async def handle_parameter_clarification(self, state: WorkflowState) -> WorkflowState:
        """å¤„ç†å‚æ•°æ¾„æ¸…æµç¨‹"""

        async def clarification_callback(data: Dict[str, Any]):
            if self.websocket_callback:
                message_type = data.get("type", "clarification_update")
                callback_data = {k: v for k, v in data.items() if k != "type"}
                await self.send_status(message_type, callback_data)

        # ä½¿ç”¨åˆ†é˜¶æ®µå‚æ•°æ”¶é›†
        from backend.src.graph.nodes.staged_parameter_clarification_node import (
            process_staged_parameter_clarification,
            process_staged_clarification_response
        )

        if state.metadata.get("awaiting_clarification", False):
            # å¤„ç†ç”¨æˆ·å›å¤
            user_messages = [msg for msg in state.messages if msg.role == "user"]
            if user_messages:
                latest_response = user_messages[-1].content
                state = await process_staged_clarification_response(
                    state,
                    latest_response,
                    clarification_callback
                )

                # æ£€æŸ¥æ˜¯å¦å®Œæˆæ‰€æœ‰é˜¶æ®µ
                if state.get_current_collection_stage() == "completed":
                    state.current_stage = "retrieve_knowledge"

                return state

        # å¼€å§‹æˆ–ç»§ç»­åˆ†é˜¶æ®µæ”¶é›†
        state = await process_staged_parameter_clarification(
            state,
            clarification_callback
        )

        if state.metadata.get("awaiting_clarification", False):
            state.current_stage = "awaiting_clarification"
        elif state.get_current_collection_stage() == "completed":
            state.current_stage = "retrieve_knowledge"

        return state


# æ›´æ–°å¯¼å‡ºå‡½æ•°
async def process_user_input_streaming(user_input: str, state: Optional[WorkflowState] = None,
                                       websocket_callback=None) -> Tuple[WorkflowState, str]:
    """æµå¼å¤„ç†ç”¨æˆ·è¾“å…¥çš„å…¥å£å‡½æ•°"""
    manager = StreamingWorkflowManager(websocket_callback)
    return await manager.process_user_input_streaming(user_input, state)


def save_state(state: WorkflowState, filepath: str) -> bool:
    """ä¿å­˜å·¥ä½œæµçŠ¶æ€åˆ°æ–‡ä»¶ï¼Œå¢å¼ºé”™è¯¯å¤„ç†å’Œæ•°æ®ç±»å‹è½¬æ¢"""
    try:
        logger.info(f"æ­£åœ¨ä¿å­˜çŠ¶æ€åˆ°: {filepath}")

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(filepath), exist_ok=True)

        # å°†çŠ¶æ€è½¬æ¢ä¸ºå­—å…¸
        state_dict = {
            "conversation_id": state.conversation_id,
            "messages": [
                {
                    "role": msg.role,
                    "content": msg.content,
                    "timestamp": float(msg.timestamp)
                }
                for msg in state.messages
            ],
            "thinking_steps": state.thinking_steps,
            "current_stage": state.current_stage,
            "metadata": state.metadata,
            "main_plan": state.main_plan,
            "alternative_plans": state.alternative_plans,
            "retrieved_knowledge": state.retrieved_knowledge
        }

        # è½¬æ¢ä¸ºJSONå¯åºåˆ—åŒ–æ ¼å¼
        logger.debug("è½¬æ¢æ•°æ®ä¸ºJSONå¯åºåˆ—åŒ–æ ¼å¼...")
        serializable_dict = convert_to_json_serializable(state_dict)

        # ä¿å­˜åˆ°æ–‡ä»¶
        logger.debug("å†™å…¥æ–‡ä»¶...")
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(serializable_dict, f, ensure_ascii=False, indent=2)

        logger.info(f"çŠ¶æ€ä¿å­˜æˆåŠŸ: {filepath}")
        return True

    except Exception as e:
        logger.error(f"ä¿å­˜çŠ¶æ€æ—¶å‡ºé”™: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        return False


def load_state(filepath: str) -> Optional[WorkflowState]:
    """ä»æ–‡ä»¶åŠ è½½å·¥ä½œæµçŠ¶æ€"""
    try:
        logger.info(f"æ­£åœ¨åŠ è½½çŠ¶æ€ä»: {filepath}")

        if not os.path.exists(filepath):
            logger.warning(f"çŠ¶æ€æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
            return None

        with open(filepath, 'r', encoding='utf-8') as f:
            state_dict = json.load(f)

        state = WorkflowState(
            conversation_id=state_dict.get("conversation_id", str(uuid.uuid4())),
            messages=[],
            thinking_steps=state_dict.get("thinking_steps", []),
            current_stage=state_dict.get("current_stage", ""),
            metadata=state_dict.get("metadata", {}),
            main_plan=state_dict.get("main_plan"),
            alternative_plans=state_dict.get("alternative_plans", []),
            retrieved_knowledge=state_dict.get("retrieved_knowledge", [])
        )

        # æ·»åŠ æ¶ˆæ¯
        for msg_dict in state_dict.get("messages", []):
            state.add_message(msg_dict["role"], msg_dict["content"])

        logger.info(f"çŠ¶æ€åŠ è½½æˆåŠŸ: {filepath}, æ¶ˆæ¯æ•°é‡: {len(state.messages)}")
        return state

    except Exception as e:
        logger.error(f"åŠ è½½çŠ¶æ€æ—¶å‡ºé”™: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        return None


if __name__ == "__main__":
    print("=" * 50)
    print("æµ‹è¯•æ”¯æŒæ‰€æœ‰æ„å›¾æµå¼è¾“å‡ºçš„å·¥ä½œæµ")
    print("=" * 50)


    async def test_streaming_workflow():
        try:
            async def test_callback(data):
                print(f"[{data['type']}] {data.get('step', '')} - {data.get('message', data.get('content', ''))}")

            state = WorkflowState()
            manager = StreamingWorkflowManager(test_callback)

            # æµ‹è¯•ä¸åŒæ„å›¾
            test_cases = [
                ("ä½ å¥½", "greeting"),
                ("ä»€ä¹ˆæ˜¯è™šæ‹Ÿæ˜Ÿåº§ï¼Ÿ", "provide_info"),
                ("æˆ‘éœ€è¦ç›‘æµ‹é’æµ·æ¹–çš„æ°´è´¨å˜åŒ–", "generate_plan"),
                ("è°¢è°¢ä½ çš„å¸®åŠ©", "thanks"),
                ("ä»Šå¤©å¤©æ°”ä¸é”™", "chat")
            ]

            for test_input, expected_intent in test_cases:
                print(f"\næµ‹è¯•è¾“å…¥: {test_input} (æœŸæœ›æ„å›¾: {expected_intent})")
                print("-" * 50)

                result_state, response = await manager.process_user_input_streaming(test_input, WorkflowState())
                print(f"å“åº”é•¿åº¦: {len(response)}")

                await asyncio.sleep(1)  # ç­‰å¾…æµå¼è¾“å‡ºå®Œæˆ

            print("\næ‰€æœ‰æµ‹è¯•å®Œæˆ!")

        except Exception as e:
            print(f"æµ‹è¯•å‡ºé”™: {str(e)}")
            import traceback
            traceback.print_exc()


    # è¿è¡Œæµ‹è¯•
    asyncio.run(test_streaming_workflow())