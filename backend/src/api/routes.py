# backend/src/api/routes.py

import os
import sys
import json
import uuid
import logging
import asyncio
import traceback
from pathlib import Path
from typing import List, Dict, Any, Optional, Union
from datetime import datetime
import time
import torch

# ç¡®ä¿é¡¹ç›®æ ¹ç›®å½•åœ¨sys.pathä¸­
current_file = Path(__file__).resolve()
project_root = current_file.parent.parent.parent.parent  # ä¸Šæº¯å››çº§ç›®å½•åˆ°é¡¹ç›®æ ¹ç›®å½•
sys.path.append(str(project_root))

# FastAPIç›¸å…³å¯¼å…¥
from fastapi import FastAPI, HTTPException, Depends, UploadFile, File, BackgroundTasks, WebSocket, WebSocketDisconnect, \
    Query, Path as PathParam, Body
from fastapi.responses import JSONResponse, FileResponse, Response
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from backend.src.tools.knowledge_tools import retrieve_knowledge_for_workflow
from backend.src.graph.nodes import buffered_streaming_planning_nodes
# é¡¹ç›®å†…éƒ¨å¯¼å…¥
from backend.config.config import settings
from backend.src.graph.state import WorkflowState, ConstellationPlan, Message
from backend.src.graph.workflow_streaming import process_user_input_streaming, save_state, load_state
from backend.src.graph.nodes.enhanced_visualization_nodes import enhance_plan_with_visualization, \
    add_visualization_to_response
from backend.config.ai_config import ai_settings
from backend.src.llm.jiuzhou_model_manager import get_jiuzhou_manager

# å¯¼å…¥å¤šæ¨¡å‹ç®¡ç†å™¨
from backend.src.llm.multi_model_manager import get_multi_model_manager

# å¯¼å…¥çˆ¬è™«æ™ºèƒ½ä½“
from backend.src.tools.crawler_agent.crawler_workflow import crawler_workflow



# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=getattr(logging, settings.log_level),
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler(settings.log_file) if settings.log_file else logging.NullHandler()
    ]
)
logger = logging.getLogger(__name__)


# ğŸ†• å¯¼å…¥æ•°æ®å¤„ç†å·¥å…·
# ğŸ†• æ•°æ®å¤„ç†å·¥å…·å¯é€‰å¯¼å…¥ï¼ˆé¿å…ç›´æ¥è¿è¡Œæ—¶æ¨¡å—è·¯å¾„é—®é¢˜ï¼‰
try:
    from backend.src.tools.data_processor import data_processor
    DATA_PROCESSOR_AVAILABLE = True
    logger.info("âœ… æ•°æ®å¤„ç†å·¥å…·åŠ è½½æˆåŠŸï¼Œå¯ç”¨å®Œæ•´æ•°æ®å¤„ç†åŠŸèƒ½")
except Exception as _e:
    data_processor = None
    DATA_PROCESSOR_AVAILABLE = False
    logger.warning(f"âš ï¸ æ•°æ®å¤„ç†å·¥å…·ä¸å¯ç”¨ï¼Œå¯ç”¨æœ€å°æ¥å£æ¨¡å¼: {_e}")
    logger.warning("ğŸ’¡ è¦å¯ç”¨å®Œæ•´åŠŸèƒ½ï¼Œè¯·å®‰è£…ä¾èµ–ï¼špip install -r requirements.txt")



# ä½¿ç”¨lifespanäº‹ä»¶å¤„ç†å™¨æ›¿ä»£å·²å¼ƒç”¨çš„on_event
from contextlib import asynccontextmanager


@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    # å¯åŠ¨æ—¶æ‰§è¡Œ
    logger.info("è™šæ‹Ÿæ˜Ÿåº§åŠ©æ‰‹æœåŠ¡å¯åŠ¨")

    # é¢„åŠ è½½ä¹å·æ¨¡å‹
    if ai_settings.jiuzhou_enabled:
        try:
            logger.info("å¼€å§‹é¢„åŠ è½½ä¹å·æ¨¡å‹...")
            manager = get_jiuzhou_manager()

            # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œå™¨åœ¨åå°åˆå§‹åŒ–ï¼Œé¿å…é˜»å¡å¯åŠ¨
            loop = asyncio.get_event_loop()

            # åˆ›å»ºä¸€ä¸ªä»»åŠ¡æ¥åˆå§‹åŒ–æ¨¡å‹
            async def init_model():
                await loop.run_in_executor(None, manager.initialize)
                logger.info("âœ… ä¹å·æ¨¡å‹é¢„åŠ è½½å®Œæˆ")

            # åˆ›å»ºåå°ä»»åŠ¡
            asyncio.create_task(init_model())

        except Exception as e:
            logger.error(f"âŒ ä¹å·æ¨¡å‹é¢„åŠ è½½å¤±è´¥: {e}")
            logger.warning("å°†åœ¨é¦–æ¬¡ä½¿ç”¨æ—¶åŠ è½½æ¨¡å‹")
    else:
        logger.info("ä¹å·æ¨¡å‹å·²ç¦ç”¨ï¼Œè·³è¿‡é¢„åŠ è½½")

    yield  # åº”ç”¨è¿è¡ŒæœŸé—´

    # å…³é—­æ—¶æ‰§è¡Œ
    logger.info("è™šæ‹Ÿæ˜Ÿåº§åŠ©æ‰‹æœåŠ¡å…³é—­")

    # æ¸…ç†ä¹å·æ¨¡å‹èµ„æº
    try:
        manager = get_jiuzhou_manager()
        if manager._initialized:
            manager.close()
            logger.info("ä¹å·æ¨¡å‹èµ„æºå·²é‡Šæ”¾")
    except Exception as e:
        logger.error(f"é‡Šæ”¾ä¹å·æ¨¡å‹èµ„æºæ—¶å‡ºé”™: {e}")


# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title=settings.app_name,
    version=settings.app_version,
    description="æ™ºæ…§è™šæ‹Ÿæ˜Ÿåº§åŠ©æ‰‹API",
    lifespan=lifespan
)

# æ·»åŠ CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.api.allowed_origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æ´»è·ƒçš„WebSocketè¿æ¥
active_connections: Dict[str, WebSocket] = {}

# åå°ä»»åŠ¡ç®¡ç†
background_tasks: Dict[str, asyncio.Task] = {}

# å¯¹è¯çŠ¶æ€ç¼“å­˜
conversation_cache: Dict[str, WorkflowState] = {}

# å…¨å±€WebSocketè¿æ¥ç®¡ç†
active_websockets: Dict[str, WebSocket] = {}

# ğŸ†• æ–°å¢ï¼šæ•°æ®å¤„ç†ä»»åŠ¡å­˜å‚¨
processing_tasks: Dict[str, Dict[str, Any]] = {}


# è¾…åŠ©å‡½æ•°ï¼šç¡®ä¿å¯¹è¯æ–‡ä»¶è·¯å¾„æœ‰æ•ˆ
def ensure_conversation_file_path(conversation_id: str) -> str:
    """ç¡®ä¿å¯¹è¯æ–‡ä»¶è·¯å¾„æœ‰æ•ˆï¼Œåˆ›å»ºå¿…è¦çš„ç›®å½•"""
    path = os.path.join(settings.data_dir, "conversations", f"{conversation_id}.json")
    os.makedirs(os.path.dirname(path), exist_ok=True)
    return path


# æ·»åŠ æ ¹è·¯å¾„å¤„ç†å‡½æ•°
@app.get("/")
async def root():
    """æ ¹è·¯å¾„å¤„ç†å‡½æ•°"""
    return {
        "message": "æ¬¢è¿ä½¿ç”¨æ™ºæ…§è™šæ‹Ÿæ˜Ÿåº§åŠ©æ‰‹API",
        "version": settings.app_version,
        "docs_url": "/docs",
        "redoc_url": "/redoc",
        "health_check": "/api/health",
        "status": "operational"
    }


# æ•°æ®æ¨¡å‹å®šä¹‰
class ConversationRequest(BaseModel):
    """å¯¹è¯è¯·æ±‚æ¨¡å‹"""
    message: str
    conversation_id: Optional[str] = None
    extracted_satellites: Optional[List[str]] = None
    location: Optional[str] = None  # ğŸ†• æ–°å¢ä½ç½®å­—æ®µ


class ConversationRenameRequest(BaseModel):
    """å¯¹è¯é‡å‘½åè¯·æ±‚æ¨¡å‹"""
    title: str


class ThinkingStep(BaseModel):
    """æ€è€ƒæ­¥éª¤æ¨¡å‹"""
    step: str
    details: Any
    timestamp: float


class ConversationResponse(BaseModel):
    """å¯¹è¯å“åº”æ¨¡å‹"""
    conversation_id: str
    message: str
    thinking_steps: Optional[List[ThinkingStep]] = None
    plan: Optional[Any] = None
    extracted_satellites: Optional[List[str]] = None
    location: Optional[str] = None
    visualization_data: Optional[Dict[str, Any]] = None  # æ–°å¢
    metadata: Dict[str, Any] = Field(default_factory=dict)


class ConversationListItem(BaseModel):
    """å¯¹è¯åˆ—è¡¨é¡¹"""
    conversation_id: str
    title: str
    created_at: float
    updated_at: float
    message_count: int


class ConversationListResponse(BaseModel):
    """å¯¹è¯åˆ—è¡¨å“åº”"""
    conversations: List[ConversationListItem]
    total: int


class FileInfoResponse(BaseModel):
    """æ–‡ä»¶ä¿¡æ¯å“åº”"""
    file_id: str
    filename: str
    content_type: str
    size: int
    upload_time: float
    metadata: Dict[str, Any] = Field(default_factory=dict)


class PlanSummaryResponse(BaseModel):
    """æ–¹æ¡ˆæ¦‚è¦å“åº”"""
    plan_id: str
    name: str
    created_at: float
    satellite_count: int
    description: str


class PlanDetailResponse(BaseModel):
    """æ–¹æ¡ˆè¯¦æƒ…å“åº”"""
    plan_id: str
    name: str
    description: str
    satellites: List[Dict[str, Any]]
    advantages: Optional[List[str]] = None
    limitations: Optional[List[str]] = None
    created_at: float
    additional_info: Dict[str, Any] = Field(default_factory=dict)


class SystemInfoResponse(BaseModel):
    """ç³»ç»Ÿä¿¡æ¯å“åº”"""
    app_name: str
    version: str
    environment: str
    uptime: float
    status: str = "operational"

class SatelliteQueryRequest(BaseModel):
    """å«æ˜ŸæŸ¥è¯¢è¯·æ±‚æ¨¡å‹"""
    query: str
    model: str = Field(default="chatgpt", description="ä½¿ç”¨çš„AIæ¨¡å‹: chatgpt, qwen, deepseek")
    satellites_context: Optional[str] = Field(default="", description="å½“å‰å«æ˜Ÿæ•°æ®ä¸Šä¸‹æ–‡")

class SatelliteQueryResponse(BaseModel):
    """å«æ˜ŸæŸ¥è¯¢å“åº”æ¨¡å‹"""
    answer: str
    filters: Dict[str, Any] = Field(default_factory=dict)
    search_query: str = ""
    model_used: str
    success: bool = True
    error_message: Optional[str] = None


class CrawlJobRequest(BaseModel):
    """çˆ¬å–ä»»åŠ¡è¯·æ±‚æ¨¡å‹"""
    target_sites: List[str] = Field(default=["Gunter's Space Page"], description="ç›®æ ‡ç½‘ç«™åˆ—è¡¨")
    keywords: List[str] = Field(default=[], description="æœç´¢å…³é”®è¯")
    max_satellites: int = Field(default=10, ge=1, le=50, description="æœ€å¤§çˆ¬å–å«æ˜Ÿæ•°é‡")


class CrawlJobResponse(BaseModel):
    """çˆ¬å–ä»»åŠ¡å“åº”æ¨¡å‹"""
    job_id: str
    status: str
    message: str
    estimated_time: Optional[int] = None


class CrawlJobStatusResponse(BaseModel):
    """çˆ¬å–ä»»åŠ¡çŠ¶æ€å“åº”æ¨¡å‹"""
    job_id: str
    status: str
    created_at: float
    started_at: Optional[float] = None
    completed_at: Optional[float] = None
    results: Optional[Dict[str, Any]] = None
    error_message: Optional[str] = None


class CrawlLogsResponse(BaseModel):
    """çˆ¬å–æ—¥å¿—å“åº”æ¨¡å‹"""
    logs: List[Dict[str, Any]]
    total: int


class CrawlStatisticsResponse(BaseModel):
    """çˆ¬å–ç»Ÿè®¡å“åº”æ¨¡å‹"""
    total_crawls: int
    total_new_satellites: int
    total_failed: int
    daily_stats: List[Dict[str, Any]]
    site_stats: List[Dict[str, Any]]
    recent_logs: List[Dict[str, Any]]


# å·¥å…·å‡½æ•°
def get_conversation_state_path(conversation_id: str) -> str:
    """è·å–å¯¹è¯çŠ¶æ€æ–‡ä»¶è·¯å¾„"""
    return os.path.join(settings.data_dir, "conversations", f"{conversation_id}.json")


def get_or_create_conversation(conversation_id: Optional[str] = None) -> WorkflowState:
    """è·å–æˆ–åˆ›å»ºå¯¹è¯çŠ¶æ€"""
    if conversation_id and conversation_id in conversation_cache:
        return conversation_cache[conversation_id]

    if conversation_id:
        # å°è¯•ä»æ–‡ä»¶åŠ è½½
        state_path = get_conversation_state_path(conversation_id)
        if os.path.exists(state_path):
            state = load_state(state_path)
            if state:
                conversation_cache[conversation_id] = state
                return state

    # åˆ›å»ºæ–°å¯¹è¯
    new_state = WorkflowState()
    new_id = conversation_id or new_state.conversation_id
    new_state.conversation_id = new_id
    conversation_cache[new_id] = new_state
    return new_state


async def save_conversation_state(state: WorkflowState):
    """ä¿å­˜å¯¹è¯çŠ¶æ€"""
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(get_conversation_state_path(state.conversation_id)), exist_ok=True)

    # ä¿å­˜åˆ°ç¼“å­˜
    conversation_cache[state.conversation_id] = state

    # ä¿å­˜åˆ°æ–‡ä»¶
    save_state(state, get_conversation_state_path(state.conversation_id))


# APIè·¯ç”±
@app.post("/api/conversation", response_model=ConversationResponse)
async def handle_conversation(
        request: ConversationRequest,
        background_tasks: BackgroundTasks
):
    """å¤„ç†å¯¹è¯è¯·æ±‚"""
    try:
        # è·å–æˆ–åˆ›å»ºå¯¹è¯çŠ¶æ€
        state = get_or_create_conversation(request.conversation_id)

        # ğŸ†• å¦‚æœè¯·æ±‚ä¸­åŒ…å«å«æ˜Ÿä¿¡æ¯ï¼Œä¿å­˜åˆ°çŠ¶æ€
        if request.extracted_satellites:
            state.set_extracted_satellites(request.extracted_satellites)

        # ğŸ†• å¦‚æœè¯·æ±‚ä¸­åŒ…å«ä½ç½®ä¿¡æ¯ï¼Œä¿å­˜åˆ°çŠ¶æ€
        if request.location:
            state.metadata["location"] = request.location

        # å¤„ç†ç”¨æˆ·è¾“å…¥
        updated_state, assistant_response = await process_user_input_streaming(request.message, state)

        # ä¿å­˜çŠ¶æ€
        background_tasks.add_task(save_conversation_state, updated_state)

        # ğŸ”§ ç§»é™¤å¯è§†åŒ–æ•°æ®ç”Ÿæˆé€»è¾‘

        # æ„å»ºå“åº”
        response = ConversationResponse(
            conversation_id=updated_state.conversation_id,
            message=assistant_response,
            thinking_steps=[ThinkingStep(**step) for step in
                            updated_state.thinking_steps] if updated_state.thinking_steps else None,
            plan=updated_state.main_plan,
            extracted_satellites=updated_state.extracted_satellites,
            location=updated_state.metadata.get("location"),
            visualization_data=None  # ğŸ”§ ä¿®æ”¹ï¼šå§‹ç»ˆè¿”å› None
        )

        return response

    except Exception as e:
        logger.error(f"å¤„ç†å¯¹è¯è¯·æ±‚æ—¶å‡ºé”™: {str(e)}")
        raise HTTPException(status_code=500, detail=f"å¤„ç†å¯¹è¯è¯·æ±‚æ—¶å‡ºé”™: {str(e)}")


@app.get("/api/conversation/{conversation_id}", response_model=ConversationResponse)
async def get_conversation(conversation_id: str = PathParam(...)):
    """è·å–å¯¹è¯è¯¦æƒ…"""
    try:
        logger.info(f"æ­£åœ¨è·å–å¯¹è¯è¯¦æƒ…: {conversation_id}")

        # è·å–æˆ–åˆ›å»ºå¯¹è¯çŠ¶æ€
        state = get_or_create_conversation(conversation_id)

        # æå–æ‰€æœ‰æ¶ˆæ¯
        messages_data = []
        for msg in state.messages:
            messages_data.append({
                "role": msg.role,
                "content": msg.content,
                "timestamp": msg.timestamp
            })

        # è·å–æœ€åä¸€æ¡åŠ©æ‰‹æ¶ˆæ¯
        last_message = ""
        for msg in reversed(state.messages):
            if msg.role == "assistant":
                last_message = msg.content
                break

        # æ„å»ºå“åº”å¯¹è±¡
        response = ConversationResponse(
            conversation_id=state.conversation_id,
            message=last_message,
            thinking_steps=[ThinkingStep(**step) for step in state.thinking_steps] if state.thinking_steps else None,
            plan=state.main_plan,
            extracted_satellites=state.extracted_satellites,
            location=state.metadata.get("location"),  # ğŸ†• è¿”å›ä½ç½®ä¿¡æ¯
            metadata={
                "message_count": len(state.messages),
                "current_stage": state.current_stage,
                "messages": messages_data
            }
        )

        logger.info(f"æˆåŠŸè·å–å¯¹è¯è¯¦æƒ…: {conversation_id}, æ¶ˆæ¯æ•°é‡: {len(messages_data)}")
        return response

    except Exception as e:
        logger.error(f"è·å–å¯¹è¯è¯¦æƒ…æ—¶å‡ºé”™: {str(e)}")
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"è·å–å¯¹è¯è¯¦æƒ…æ—¶å‡ºé”™: {str(e)}")


@app.get("/api/conversations", response_model=ConversationListResponse)
async def list_conversations(
        limit: int = Query(10, ge=1, le=100),
        offset: int = Query(0, ge=0)
):
    """è·å–å¯¹è¯åˆ—è¡¨"""
    try:
        # è·å–å¯¹è¯æ–‡ä»¶åˆ—è¡¨
        conversations_dir = os.path.join(settings.data_dir, "conversations")
        os.makedirs(conversations_dir, exist_ok=True)

        logger.info(f"æ­£åœ¨è·å–å¯¹è¯åˆ—è¡¨ï¼Œç›®å½•: {conversations_dir}")

        # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
        conversation_files = []
        if os.path.exists(conversations_dir):
            conversation_files = [f for f in os.listdir(conversations_dir) if f.endswith('.json')]
            logger.info(f"æ‰¾åˆ° {len(conversation_files)} ä¸ªå¯¹è¯æ–‡ä»¶")
        else:
            logger.warning(f"å¯¹è¯ç›®å½•ä¸å­˜åœ¨: {conversations_dir}")
            return ConversationListResponse(conversations=[], total=0)

        # åŠ è½½å¯¹è¯æ•°æ®
        conversations = []
        total = len(conversation_files)

        for filename in conversation_files[offset:offset + limit]:
            try:
                conversation_id = filename.replace('.json', '')
                state_path = os.path.join(conversations_dir, filename)

                # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§å’Œå¤§å°
                if not os.path.exists(state_path):
                    logger.warning(f"å¯¹è¯æ–‡ä»¶ä¸å­˜åœ¨: {state_path}")
                    continue

                file_size = os.path.getsize(state_path)
                logger.info(f"åŠ è½½å¯¹è¯æ–‡ä»¶: {state_path}, å¤§å°: {file_size} å­—èŠ‚")

                # è¯»å–å¹¶éªŒè¯æ–‡ä»¶å†…å®¹æ˜¯å¦æœ‰æ•ˆ
                try:
                    with open(state_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    # å°è¯•è§£æä¸ºJSON
                    json.loads(content)
                except Exception as e:
                    logger.error(f"å¯¹è¯æ–‡ä»¶ {filename} å†…å®¹æ— æ•ˆ: {str(e)}")
                    continue

                # åŠ è½½çŠ¶æ€
                state = load_state(state_path)

                if state:
                    # ä¼˜å…ˆä½¿ç”¨è‡ªå®šä¹‰æ ‡é¢˜
                    if state.metadata and state.metadata.get("custom_title"):
                        title = state.metadata["custom_title"]
                    else:
                        # ä½¿ç”¨ç¬¬ä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ä½œä¸ºæ ‡é¢˜
                        title = "æ–°å¯¹è¯"
                        for msg in state.messages:
                            if msg.role == "user":
                                title = msg.content[:50] + ("..." if len(msg.content) > 50 else "")
                                break

                    # æå–æ—¶é—´æˆ³
                    created_at = 0
                    updated_at = 0
                    if state.messages:
                        created_at = state.messages[0].timestamp
                        updated_at = state.messages[-1].timestamp

                    conversations.append(ConversationListItem(
                        conversation_id=conversation_id,
                        title=title,
                        created_at=created_at,
                        updated_at=updated_at,
                        message_count=len(state.messages)
                    ))
                    logger.info(f"æˆåŠŸåŠ è½½å¯¹è¯: {conversation_id}, æ ‡é¢˜: {title}, æ¶ˆæ¯æ•°é‡: {len(state.messages)}")
                else:
                    logger.warning(f"æ— æ³•åŠ è½½å¯¹è¯çŠ¶æ€: {state_path}")
            except Exception as e:
                logger.error(f"åŠ è½½å¯¹è¯ {filename} æ—¶å‡ºé”™: {str(e)}")
                logger.error(traceback.format_exc())  # æ·»åŠ å®Œæ•´å †æ ˆè·Ÿè¸ª

        # æŒ‰æ›´æ–°æ—¶é—´æ’åº
        conversations.sort(key=lambda x: x.updated_at, reverse=True)

        logger.info(f"æˆåŠŸåŠ è½½ {len(conversations)} ä¸ªå¯¹è¯ï¼Œè¿”å›ç»™å‰ç«¯")
        return ConversationListResponse(
            conversations=conversations,
            total=total
        )

    except Exception as e:
        logger.error(f"è·å–å¯¹è¯åˆ—è¡¨æ—¶å‡ºé”™: {str(e)}")
        logger.error(traceback.format_exc())  # æ·»åŠ å®Œæ•´å †æ ˆè·Ÿè¸ª
        raise HTTPException(status_code=500, detail=f"è·å–å¯¹è¯åˆ—è¡¨æ—¶å‡ºé”™: {str(e)}")


@app.patch("/api/conversation/{conversation_id}/rename")
async def rename_conversation(
        request: ConversationRenameRequest,
        conversation_id: str = PathParam(...)
):
    """é‡å‘½åå¯¹è¯"""
    try:
        if not request or not request.title or not request.title.strip():
            raise HTTPException(status_code=400, detail="æ ‡é¢˜ä¸èƒ½ä¸ºç©º")

        new_title = request.title.strip()

        # ä»ç¼“å­˜æˆ–æ–‡ä»¶ä¸­è·å–å¯¹è¯
        state = get_or_create_conversation(conversation_id)
        if not state:
            raise HTTPException(status_code=404, detail=f"å¯¹è¯ {conversation_id} ä¸å­˜åœ¨")

        # æ›´æ–°å…ƒæ•°æ®ä¸­çš„æ ‡é¢˜
        if not state.metadata:
            state.metadata = {}
        state.metadata["custom_title"] = new_title
        state.metadata["title_updated_at"] = datetime.now().timestamp()

        # ä¿å­˜æ›´æ–°åçš„çŠ¶æ€
        await save_conversation_state(state)

        # æ›´æ–°ç¼“å­˜ä¸­çš„å¯¹è¯
        if conversation_id in conversation_cache:
            conversation_cache[conversation_id] = state

        logger.info(f"å¯¹è¯ {conversation_id} é‡å‘½åä¸º: {new_title}")

        return {
            "status": "success",
            "conversation_id": conversation_id,
            "new_title": new_title,
            "message": "å¯¹è¯é‡å‘½åæˆåŠŸ"
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"é‡å‘½åå¯¹è¯æ—¶å‡ºé”™: {str(e)}")
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"é‡å‘½åå¯¹è¯æ—¶å‡ºé”™: {str(e)}")


@app.post("/api/conversation/create", response_model=ConversationResponse)
async def create_empty_conversation(
        conversation_id: str = Body(..., embed=True)
):
    """åˆ›å»ºç©ºå¯¹è¯ - ä¸å¤„ç†ä»»ä½•æ¶ˆæ¯"""
    try:
        logger.info(f"åˆ›å»ºç©ºå¯¹è¯: {conversation_id}")

        # åˆ›å»ºæ–°çš„å¯¹è¯çŠ¶æ€
        state = WorkflowState()
        state.conversation_id = conversation_id

        # ä¿å­˜ç©ºå¯¹è¯çŠ¶æ€
        await save_conversation_state(state)

        # æ„å»ºå“åº”
        response = ConversationResponse(
            conversation_id=state.conversation_id,
            message="",
            thinking_steps=None,
            plan=None,
            extracted_satellites=[],
            location=None,
            visualization_data=None,
            metadata={
                "message_count": 0,
                "current_stage": "initialized",
                "messages": []
            }
        )

        logger.info(f"æˆåŠŸåˆ›å»ºç©ºå¯¹è¯: {conversation_id}")
        return response

    except Exception as e:
        logger.error(f"åˆ›å»ºç©ºå¯¹è¯æ—¶å‡ºé”™: {str(e)}")
        raise HTTPException(status_code=500, detail=f"åˆ›å»ºç©ºå¯¹è¯æ—¶å‡ºé”™: {str(e)}")


@app.delete("/api/conversation/{conversation_id}")
async def delete_conversation(conversation_id: str = PathParam(...)):
    """åˆ é™¤å¯¹è¯"""
    try:
        # ä»ç¼“å­˜ä¸­åˆ é™¤
        if conversation_id in conversation_cache:
            del conversation_cache[conversation_id]

        # ä»æ–‡ä»¶ä¸­åˆ é™¤
        state_path = get_conversation_state_path(conversation_id)
        if os.path.exists(state_path):
            os.remove(state_path)
            return {"status": "success", "message": f"å¯¹è¯ {conversation_id} å·²åˆ é™¤"}
        else:
            raise HTTPException(status_code=404, detail=f"å¯¹è¯ {conversation_id} ä¸å­˜åœ¨")

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"åˆ é™¤å¯¹è¯æ—¶å‡ºé”™: {str(e)}")
        logger.error(traceback.format_exc())  # æ·»åŠ å®Œæ•´å †æ ˆè·Ÿè¸ª
        raise HTTPException(status_code=500, detail=f"åˆ é™¤å¯¹è¯æ—¶å‡ºé”™: {str(e)}")


@app.post("/api/files/upload", response_model=FileInfoResponse)
async def upload_file(
        file: UploadFile = File(...),
        conversation_id: Optional[str] = None
):
    """ä¸Šä¼ æ–‡ä»¶"""
    try:
        # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶ID
        file_id = str(uuid.uuid4())

        # ç¡®ä¿ä¸Šä¼ ç›®å½•å­˜åœ¨
        upload_dir = settings.file_processor.upload_dir
        os.makedirs(upload_dir, exist_ok=True)

        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        file_size = 0
        content = await file.read()
        file_size = len(content)

        if file_size > settings.file_processor.max_file_size:
            raise HTTPException(status_code=413,
                                detail=f"æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶ ({file_size} > {settings.file_processor.max_file_size} å­—èŠ‚)")

        # è·å–æ–‡ä»¶æ‰©å±•å
        filename = file.filename
        ext = os.path.splitext(filename)[1].lower() if filename else ""

        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        if ext not in settings.file_processor.allowed_extensions:
            raise HTTPException(status_code=415, detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {ext}")

        # ä¿å­˜æ–‡ä»¶
        file_path = os.path.join(upload_dir, f"{file_id}{ext}")
        with open(file_path, "wb") as f:
            f.write(content)

        # å¦‚æœæä¾›äº†å¯¹è¯IDï¼Œå°†æ–‡ä»¶ä¸å¯¹è¯å…³è”
        if conversation_id:
            state = get_or_create_conversation(conversation_id)

            # åœ¨å…ƒæ•°æ®ä¸­è®°å½•ä¸Šä¼ çš„æ–‡ä»¶
            if "uploaded_files" not in state.metadata:
                state.metadata["uploaded_files"] = []

            state.metadata["uploaded_files"].append({
                "file_id": file_id,
                "filename": filename,
                "upload_time": datetime.now().timestamp()
            })

            # ä¿å­˜æ›´æ–°åçš„çŠ¶æ€
            await save_conversation_state(state)

        # æ„å»ºå“åº”
        response = FileInfoResponse(
            file_id=file_id,
            filename=filename or "unknown",
            content_type=file.content_type or "application/octet-stream",
            size=file_size,
            upload_time=datetime.now().timestamp(),
            metadata={
                "conversation_id": conversation_id,
                "extension": ext
            }
        )

        return response

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ä¸Šä¼ æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
        logger.error(traceback.format_exc())  # æ·»åŠ å®Œæ•´å †æ ˆè·Ÿè¸ª
        raise HTTPException(status_code=500, detail=f"ä¸Šä¼ æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")


@app.get("/api/files/{file_id}")
async def get_file(file_id: str = PathParam(...)):
    """è·å–ä¸Šä¼ çš„æ–‡ä»¶"""
    try:
        # åœ¨ä¸Šä¼ ç›®å½•ä¸­æŸ¥æ‰¾æ–‡ä»¶
        upload_dir = settings.file_processor.upload_dir

        # æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„æ–‡ä»¶æ‰©å±•å
        for ext in settings.file_processor.allowed_extensions:
            file_path = os.path.join(upload_dir, f"{file_id}{ext}")
            if os.path.exists(file_path):
                return FileResponse(
                    path=file_path,
                    filename=os.path.basename(file_path),
                    media_type="application/octet-stream"
                )

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ–‡ä»¶
        raise HTTPException(status_code=404, detail=f"æ–‡ä»¶ {file_id} ä¸å­˜åœ¨")

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
        logger.error(traceback.format_exc())  # æ·»åŠ å®Œæ•´å †æ ˆè·Ÿè¸ª
        raise HTTPException(status_code=500, detail=f"è·å–æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")


@app.delete("/api/files/{file_id}")
async def delete_file(file_id: str = PathParam(...)):
    """åˆ é™¤ä¸Šä¼ çš„æ–‡ä»¶"""
    try:
        # åœ¨ä¸Šä¼ ç›®å½•ä¸­æŸ¥æ‰¾æ–‡ä»¶
        upload_dir = settings.file_processor.upload_dir
        deleted = False

        # æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„æ–‡ä»¶æ‰©å±•å
        for ext in settings.file_processor.allowed_extensions:
            file_path = os.path.join(upload_dir, f"{file_id}{ext}")
            if os.path.exists(file_path):
                os.remove(file_path)
                deleted = True
                break

        if deleted:
            return {"status": "success", "message": f"æ–‡ä»¶ {file_id} å·²åˆ é™¤"}
        else:
            raise HTTPException(status_code=404, detail=f"æ–‡ä»¶ {file_id} ä¸å­˜åœ¨")

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"åˆ é™¤æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
        logger.error(traceback.format_exc())  # æ·»åŠ å®Œæ•´å †æ ˆè·Ÿè¸ª
        raise HTTPException(status_code=500, detail=f"åˆ é™¤æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")


@app.get("/api/ai/status")
async def get_ai_status():
    """è·å–AIæ¨¡å‹çŠ¶æ€"""
    try:
        from backend.src.llm.jiuzhou_model_manager import get_jiuzhou_manager
        from backend.config.ai_config import ai_settings

        manager = get_jiuzhou_manager()

        return {
            "jiuzhou_enabled": ai_settings.jiuzhou_enabled,
            "jiuzhou_initialized": manager._initialized,
            "model_path": ai_settings.jiuzhou_model_path,
            "device": str(manager.device) if manager._initialized else "not_loaded"
        }
    except Exception as e:
        logger.error(f"è·å–AIçŠ¶æ€å¤±è´¥: {e}")
        return {
            "error": str(e),
            "jiuzhou_enabled": False,
            "jiuzhou_initialized": False
        }


@app.get("/api/ai/model-status")
async def get_model_status():
    """è·å–AIæ¨¡å‹è¯¦ç»†çŠ¶æ€"""
    try:
        from backend.src.llm.jiuzhou_model_manager import get_jiuzhou_manager
        from backend.config.ai_config import ai_settings

        manager = get_jiuzhou_manager()

        status = {
            "jiuzhou_enabled": ai_settings.jiuzhou_enabled,
            "jiuzhou_initialized": manager._initialized,
            "model_path": ai_settings.jiuzhou_model_path,
            "model_exists": os.path.exists(ai_settings.jiuzhou_model_path),
            "device": str(manager.device) if manager._initialized else "not_loaded",
            "cuda_available": torch.cuda.is_available(),
            "cuda_device_count": torch.cuda.device_count() if torch.cuda.is_available() else 0
        }

        if manager._initialized and manager.model:
            try:
                # è·å–æ¨¡å‹å¤§å°ä¿¡æ¯
                model_size = sum(p.numel() for p in manager.model.parameters())
                status["model_parameters"] = f"{model_size:,}"
                status["model_memory_mb"] = f"{model_size * 4 / 1024 / 1024:.2f}"  # å‡è®¾float32
            except:
                pass

        return status

    except Exception as e:
        logger.error(f"è·å–æ¨¡å‹çŠ¶æ€å¤±è´¥: {e}")
        return {
            "error": str(e),
            "jiuzhou_enabled": False,
            "jiuzhou_initialized": False
        }


@app.get("/api/plans/{plan_id}", response_model=PlanDetailResponse)
async def get_plan(plan_id: str = PathParam(...)):
    """è·å–æ˜Ÿåº§æ–¹æ¡ˆè¯¦æƒ…"""
    try:
        # éå†æ‰€æœ‰å¯¹è¯æ‰¾åˆ°è¯¥æ–¹æ¡ˆ
        for state in conversation_cache.values():
            if state.main_plan and isinstance(state.main_plan, dict) and state.main_plan.get("plan_id") == plan_id:
                plan = state.main_plan
                return PlanDetailResponse(
                    plan_id=plan.get("plan_id", plan_id),
                    name=plan.get("name", "æœªå‘½åæ–¹æ¡ˆ"),
                    description=plan.get("description", ""),
                    satellites=plan.get("satellites", []),
                    advantages=plan.get("advantages", []),
                    limitations=plan.get("limitations", []),
                    created_at=plan.get("created_at", datetime.now().timestamp()),
                    additional_info=plan.get("additional_info", {})
                )

            # æ£€æŸ¥å¤‡é€‰æ–¹æ¡ˆ
            for alt_plan in state.alternative_plans:
                if isinstance(alt_plan, dict) and alt_plan.get("plan_id") == plan_id:
                    return PlanDetailResponse(
                        plan_id=alt_plan.get("plan_id", plan_id),
                        name=alt_plan.get("name", "æœªå‘½åæ–¹æ¡ˆ"),
                        description=alt_plan.get("description", ""),
                        satellites=alt_plan.get("satellites", []),
                        advantages=alt_plan.get("advantages", []),
                        limitations=alt_plan.get("limitations", []),
                        created_at=alt_plan.get("created_at", datetime.now().timestamp()),
                        additional_info=alt_plan.get("additional_info", {})
                    )

        # å¦‚æœæ–¹æ¡ˆä¸åœ¨ç¼“å­˜ä¸­ï¼Œå°è¯•ä»æ–‡ä»¶åŠ è½½
        conversations_dir = os.path.join(settings.data_dir, "conversations")
        if os.path.exists(conversations_dir):
            for filename in os.listdir(conversations_dir):
                if filename.endswith('.json'):
                    state_path = os.path.join(conversations_dir, filename)
                    state = load_state(state_path)

                    if state and state.main_plan and isinstance(state.main_plan, dict) and state.main_plan.get(
                            "plan_id") == plan_id:
                        plan = state.main_plan
                        return PlanDetailResponse(
                            plan_id=plan.get("plan_id", plan_id),
                            name=plan.get("name", "æœªå‘½åæ–¹æ¡ˆ"),
                            description=plan.get("description", ""),
                            satellites=plan.get("satellites", []),
                            advantages=plan.get("advantages", []),
                            limitations=plan.get("limitations", []),
                            created_at=plan.get("created_at", datetime.now().timestamp()),
                            additional_info=plan.get("additional_info", {})
                        )

        # å¦‚æœæœªæ‰¾åˆ°æ–¹æ¡ˆ
        raise HTTPException(status_code=404, detail=f"æ–¹æ¡ˆ {plan_id} ä¸å­˜åœ¨")

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–æ–¹æ¡ˆè¯¦æƒ…æ—¶å‡ºé”™: {str(e)}")
        logger.error(traceback.format_exc())  # æ·»åŠ å®Œæ•´å †æ ˆè·Ÿè¸ª
        raise HTTPException(status_code=500, detail=f"è·å–æ–¹æ¡ˆè¯¦æƒ…æ—¶å‡ºé”™: {str(e)}")

@app.post("/api/satellite/query", response_model=SatelliteQueryResponse)
async def query_satellites(request: SatelliteQueryRequest):
    """æ™ºèƒ½å«æ˜ŸæŸ¥è¯¢æ¥å£"""
    try:
        logger.info(f"æ”¶åˆ°å«æ˜ŸæŸ¥è¯¢è¯·æ±‚: {request.query[:100]}... ä½¿ç”¨æ¨¡å‹: {request.model}")
        
        # è·å–å¤šæ¨¡å‹ç®¡ç†å™¨
        manager = get_multi_model_manager()
        
        # æŸ¥è¯¢å«æ˜Ÿä¿¡æ¯
        result = await manager.query_satellite_info(
            user_query=request.query,
            model_name=request.model,
            satellites_context=request.satellites_context
        )
        
        # æ„å»ºå“åº”
        response = SatelliteQueryResponse(
            answer=result.get("answer", "å¤„ç†å®Œæˆ"),
            filters=result.get("filters", {}),
            search_query=result.get("search_query", ""),
            model_used=request.model,
            success=True
        )
        
        logger.info(f"å«æ˜ŸæŸ¥è¯¢æˆåŠŸ: {request.model}")
        return response
        
    except Exception as e:
        logger.error(f"å«æ˜ŸæŸ¥è¯¢å¤±è´¥: {str(e)}")
        logger.error(traceback.format_exc())
        
        # è¿”å›é”™è¯¯å“åº”ä½†ä¸æŠ›å‡ºå¼‚å¸¸
        return SatelliteQueryResponse(
            answer=f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„æŸ¥è¯¢æ—¶å‡ºç°é”™è¯¯: {str(e)}",
            filters={},
            search_query="",
            model_used=request.model,
            success=False,
            error_message=str(e)
        )


@app.get("/api/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    try:
        start_time = datetime.now().timestamp()

        # æ£€æŸ¥çŸ¥è¯†åº“
        try:
            from backend.src.rag.knowledge_base import get_knowledge_base
            kb = get_knowledge_base()
            kb_status = "operational" if hasattr(kb, "vector_store") and kb.vector_store is not None else "degraded"
        except Exception as e:
            logger.error(f"æ£€æŸ¥çŸ¥è¯†åº“çŠ¶æ€æ—¶å‡ºé”™: {str(e)}")
            kb_status = "error"

        # æ£€æŸ¥APIå¯†é’¥
        llm_status = "operational" if settings.llm.api_key else "degraded"

        return {
            "status": "operational",
            "services": {
                "api": "operational",
                "knowledge_base": kb_status,
                "llm": llm_status
            },
            "uptime": start_time - startup_time,
            "version": settings.app_version
        }

    except Exception as e:
        logger.error(f"å¥åº·æ£€æŸ¥æ—¶å‡ºé”™: {str(e)}")
        logger.error(traceback.format_exc())  # æ·»åŠ å®Œæ•´å †æ ˆè·Ÿè¸ª
        return {
            "status": "degraded",
            "error": str(e),
            "version": settings.app_version
        }


# è°ƒè¯•ç«¯ç‚¹
@app.get("/api/debug/conversations")
async def debug_conversations():
    """è°ƒè¯•ç”¨ï¼šè·å–å¯¹è¯ç›®å½•ä¿¡æ¯"""
    try:
        conversations_dir = os.path.join(settings.data_dir, "conversations")
        exists = os.path.exists(conversations_dir)
        files = []
        file_details = []

        if exists:
            files = [f for f in os.listdir(conversations_dir) if f.endswith('.json')]
            for f in files[:5]:  # åªè·å–å‰5ä¸ªæ–‡ä»¶çš„è¯¦æƒ…
                path = os.path.join(conversations_dir, f)
                size = os.path.getsize(path) if os.path.exists(path) else 0
                file_details.append({"name": f, "size": size})

        return {
            "directory": conversations_dir,
            "exists": exists,
            "file_count": len(files),
            "file_samples": file_details if exists else [],
            "data_dir": settings.data_dir,
            "cache_size": len(conversation_cache)
        }
    except Exception as e:
        logger.error(f"è·å–è°ƒè¯•ä¿¡æ¯æ—¶å‡ºé”™: {str(e)}")
        logger.error(traceback.format_exc())  # æ·»åŠ å®Œæ•´å †æ ˆè·Ÿè¸ª
        return {"error": str(e)}


@app.get("/api/debug/conversation/{conversation_id}")
async def debug_conversation(conversation_id: str = PathParam(...)):
    """è°ƒè¯•ç”¨ï¼šè·å–å¯¹è¯æ–‡ä»¶ä¿¡æ¯"""
    try:
        file_path = get_conversation_state_path(conversation_id)
        exists = os.path.exists(file_path)
        in_cache = conversation_id in conversation_cache

        response_data = {
            "file_path": file_path,
            "exists": exists,
            "in_cache": in_cache
        }

        if exists:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                file_size = len(content)
                response_data["file_size"] = file_size

                # å°è¯•è§£æJSON
                try:
                    json_content = json.loads(content)
                    response_data["json_valid"] = True
                    response_data["message_count"] = len(json_content.get("messages", []))

                    if json_content.get("messages") and len(json_content.get("messages")) > 0:
                        response_data["sample_message"] = json_content.get("messages")[0]
                except json.JSONDecodeError as e:
                    response_data["json_valid"] = False
                    response_data["error"] = "æ— æ³•è§£æJSONå†…å®¹"
                    response_data["json_error"] = str(e)
                    response_data["content_preview"] = content[:100] + "..." if len(content) > 100 else content

        if in_cache:
            state = conversation_cache[conversation_id]
            response_data["cache_message_count"] = len(state.messages)
            response_data["cache_first_user_message"] = next(
                (msg.content for msg in state.messages if msg.role == "user"), None)

        return response_data
    except Exception as e:
        logger.error(f"è°ƒè¯•å¯¹è¯æ—¶å‡ºé”™: {str(e)}")
        logger.error(traceback.format_exc())  # æ·»åŠ å®Œæ•´å †æ ˆè·Ÿè¸ª
        return {
            "error": str(e),
            "traceback": traceback.format_exc()
        }


# åœ¨ routes.py ä¸­ç®€åŒ–WebSocketå¤„ç†

@app.websocket("/api/ws/{conversation_id}")
async def websocket_endpoint(websocket: WebSocket, conversation_id: str):
    """å®æ—¶æµå¼WebSocketç«¯ç‚¹"""
    await websocket.accept()

    # å­˜å‚¨è¿æ¥
    active_websockets[conversation_id] = websocket

    # å‘é€è¿æ¥ç¡®è®¤
    await websocket.send_json({
        "type": "connected",
        "conversation_id": conversation_id,
        "message": "WebSocketè¿æ¥å·²å»ºç«‹"
    })

    try:
        while True:
            # æ¥æ”¶ç”¨æˆ·æ¶ˆæ¯
            data = await websocket.receive_text()
            message_data = json.loads(data)
            message_type = message_data.get("type", "message")
            
            # ğŸ†• æ–°å¢ï¼šå¤„ç†ä¸åŒç±»å‹çš„æ¶ˆæ¯
            if message_type == "data_processing_complete":
                # å¤„ç†æ•°æ®å¤„ç†å®Œæˆæ¶ˆæ¯ï¼ˆæ¥è‡ªå‰ç«¯çš„é€šçŸ¥ï¼Œè°¨æ…åˆå¹¶ï¼Œé¿å…è¦†ç›–åç«¯çœŸå®ç»“æœè·¯å¾„ï¼‰
                processing_id = message_data.get("processing_id")
                client_results = message_data.get("results", {})

                if processing_id and processing_id in processing_tasks:
                    task_ref = processing_tasks[processing_id]

                    # ä»…åˆå¹¶éç©ºå­—æ®µï¼Œä¿ç•™åç«¯å†™å…¥çš„ original_data/processed_data/result_package
                    existing_results = task_ref.get("results", {}) or {}
                    merged_results = dict(existing_results)
                    for k, v in (client_results or {}).items():
                        if v is not None:
                            merged_results[k] = v

                    task_ref["results"] = merged_results

                    # çŠ¶æ€ä»¥åå°ä»»åŠ¡ä¸ºå‡†ï¼Œè¿™é‡Œä¸å¼ºåˆ¶è¦†ç›–
                    await websocket.send_json({
                        "type": "data_processing_complete",
                        "message": "æ•°æ®å¤„ç†çŠ¶æ€å·²åˆå¹¶",
                        "processing_id": processing_id
                    })
                continue
            
            user_message = message_data.get("message", "")
            extracted_satellites = message_data.get("extracted_satellites", [])
            location = message_data.get("location")

            if not user_message:
                await websocket.send_json({
                    "type": "error",
                    "message": "æ¶ˆæ¯ä¸èƒ½ä¸ºç©º"
                })
                continue
            print('hhhhhhhh',user_message)
            # è·å–æˆ–åˆ›å»ºå¯¹è¯çŠ¶æ€
            state = get_or_create_conversation(conversation_id)

            # ğŸ†• æ£€æµ‹æ˜¯å¦æ˜¯æ–°æ–¹æ¡ˆè¯·æ±‚
            # is_new_plan_request = any(keyword in user_message.lower() for keyword in [
            #     "ç›‘æµ‹", "æ–¹æ¡ˆ", "è§„åˆ’", "è®¾è®¡", "è§‚æµ‹", "åˆ†æ", "æŸ¥çœ‹"
            # ])

            # ğŸ”§ å…³é”®ä¿®å¤ï¼šå¦‚æœæ˜¯æ–°æ–¹æ¡ˆè¯·æ±‚ä¸”å·²æœ‰æ–¹æ¡ˆï¼Œé‡ç½®æ¾„æ¸…çŠ¶æ€
            # if is_new_plan_request and state.main_plan:
            #     logger.info("ğŸ”„ æ£€æµ‹åˆ°æ–°æ–¹æ¡ˆè¯·æ±‚ï¼Œé‡ç½®å‚æ•°æ¾„æ¸…çŠ¶æ€")
            #     state.metadata["clarification_completed"] = False
            #     state.metadata["clarification_skipped"] = False
            #     state.metadata["extracted_parameters"] = {}
            #     state.metadata["awaiting_clarification"] = False
            #     state.set_extracted_satellites([])
            #
            #     # é‡ç½®å‚æ•°æ”¶é›†é˜¶æ®µ
            #     state.parameter_collection_stage = "not_started"
            #     state.parameter_collection_history = []
            #     state.stage_retry_count = {}
            #
            #     # ğŸ†• å…³é”®ï¼šæ ‡è®°æ–°æ–¹æ¡ˆè¯·æ±‚çš„èµ·å§‹ä½ç½®
            #     state.mark_new_plan_request()

            # ğŸ†• ä¿å­˜ä½ç½®ä¿¡æ¯
            if location:
                state.metadata["location"] = location

            # å‘é€å¼€å§‹å¤„ç†ä¿¡å·
            await websocket.send_json({
                "type": "processing_start",
                "message": "å¼€å§‹å¤„ç†æ‚¨çš„æ¶ˆæ¯..."
            })

            # åˆå§‹åŒ–å˜é‡
            updated_state = state
            assistant_response = ""

            try:
                # å®šä¹‰WebSocketå›è°ƒå‡½æ•°
                async def websocket_callback(data):
                    """WebSocketæ¶ˆæ¯å‘é€å›è°ƒ"""
                    try:
                        await websocket.send_json(data)
                    except Exception as e:
                        logger.error(f"å‘é€WebSocketæ¶ˆæ¯å¤±è´¥: {str(e)}")

                # ä½¿ç”¨æµå¼å¤„ç†
                updated_state, assistant_response = await process_user_input_streaming(
                    user_message,
                    state,
                    websocket_callback
                )

                # ä¿å­˜çŠ¶æ€
                await save_conversation_state(updated_state)

                # ğŸ†• ç¡®ä¿è¿”å›æœ€æ–°çš„å«æ˜Ÿä¿¡æ¯
                final_satellites = updated_state.extracted_satellites

                # å¦‚æœçŠ¶æ€ä¸­æ²¡æœ‰å«æ˜Ÿä½†å“åº”ä¸­æœ‰æ–¹æ¡ˆï¼Œå°è¯•æå–
                if not final_satellites and assistant_response and (
                        "å«æ˜Ÿç»„æˆ" in assistant_response or
                        "è™šæ‹Ÿæ˜Ÿåº§æ–¹æ¡ˆ" in assistant_response
                ):
                    # å¯¼å…¥æå–å‡½æ•°
                    from backend.src.graph.workflow_streaming import extract_satellites_from_plan
                    final_satellites = await extract_satellites_from_plan(assistant_response)
                    if final_satellites:
                        updated_state.set_extracted_satellites(final_satellites)
                        await save_conversation_state(updated_state)

                # ğŸ”§ å…³é”®ä¿®æ”¹ï¼šè·å–æ„å›¾ä¿¡æ¯
                current_intent = updated_state.metadata.get("intent", "unknown")
                has_streamed_response = current_intent in ["provide_info", "greeting", "thanks", "chat",]
                # ğŸ”§ å…³é”®ä¿®æ”¹ï¼šåªåœ¨ç‰¹å®šæ„å›¾æ—¶ä¼ é€’å«æ˜Ÿå’Œä½ç½®ä¿¡æ¯
                should_show_map = current_intent in ["generate_plan", "optimize_plan"]

                completion_data = {
                    "type": "processing_complete",
                    "conversation_id": updated_state.conversation_id,
                    "response": assistant_response if not has_streamed_response else None,
                    "intent": current_intent,  # ğŸ”§ æ–°å¢ï¼šä¼ é€’æ„å›¾ä¿¡æ¯
                    "message": "å¤„ç†å®Œæˆ"
                }

                # ğŸ”§ å…³é”®ä¿®æ”¹ï¼šåªåœ¨åº”è¯¥æ˜¾ç¤ºåœ°å›¾æ—¶æ‰ä¼ é€’å«æ˜Ÿå’Œä½ç½®ä¿¡æ¯
                if should_show_map:
                    completion_data.update({
                        "extracted_satellites": [],
                        "location": updated_state.metadata.get("location"),
                        "show_map": True  # ğŸ”§ æ–°å¢ï¼šæ˜ç¡®æŒ‡ç¤ºæ˜¯å¦æ˜¾ç¤ºåœ°å›¾
                    })
                else:
                    completion_data.update({
                        "extracted_satellites": [],  # ğŸ”§ ä¸æ˜¾ç¤ºåœ°å›¾æ—¶ä¼ é€’ç©ºåˆ—è¡¨
                        "location": None,
                        "show_map": False  # ğŸ”§ æ˜ç¡®æŒ‡ç¤ºä¸æ˜¾ç¤ºåœ°å›¾
                    })

                # å‘é€æœ€ç»ˆå®Œæˆä¿¡å·
                await websocket.send_json(completion_data)

            except Exception as e:
                logger.error(f"å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™: {str(e)}")
                logger.error(traceback.format_exc())

                error_message = f"å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™: {str(e)}"
                updated_state.add_message("assistant", f"æŠ±æ­‰ï¼Œ{error_message}")

                try:
                    await save_conversation_state(updated_state)
                except:
                    pass

                await websocket.send_json({
                    "type": "error",
                    "message": error_message,
                    "response": f"æŠ±æ­‰ï¼Œ{error_message}",
                    "conversation_id": conversation_id
                })

    except WebSocketDisconnect:
        logger.info(f"WebSocketæ–­å¼€è¿æ¥: {conversation_id}")
        if conversation_id in active_websockets:
            del active_websockets[conversation_id]
    except Exception as e:
        logger.error(f"WebSocketé”™è¯¯: {str(e)}")
        logger.error(traceback.format_exc())
        if conversation_id in active_websockets:
            del active_websockets[conversation_id]


async def process_message_streaming(websocket: WebSocket, state: WorkflowState, user_message: str):
    """æµå¼å¤„ç†æ¶ˆæ¯ - ç®€åŒ–ç‰ˆæœ¬"""
    try:
        # 1. å‘é€å¼€å§‹ä¿¡å·
        await websocket.send_json({
            "type": "processing_start",
            "message": "å¼€å§‹å¤„ç†æ‚¨çš„æ¶ˆæ¯..."
        })

        # 2. æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        state.add_message("user", user_message)

        # 3. å‘é€æ€è€ƒæ­¥éª¤
        await websocket.send_json({
            "type": "thinking_step",
            "step": "æ„å›¾åˆ†æ",
            "message": "æ­£åœ¨åˆ†ææ‚¨çš„è¯·æ±‚æ„å›¾..."
        })

        await asyncio.sleep(0.5)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´

        # 4. æ„å›¾åˆ†æï¼ˆç®€åŒ–ï¼‰
        intent = analyze_intent_simple(user_message, state)

        await websocket.send_json({
            "type": "thinking_step",
            "step": "æ„å›¾è¯†åˆ«",
            "message": f"è¯†åˆ«åˆ°æ„å›¾: {intent}"
        })

        # 5. æ ¹æ®æ„å›¾å¤„ç†
        if intent == "generate_plan":
            await websocket.send_json({
                "type": "thinking_step",
                "step": "çŸ¥è¯†æ£€ç´¢",
                "message": "æ­£åœ¨æ£€ç´¢ç›¸å…³å«æ˜ŸçŸ¥è¯†..."
            })

            await asyncio.sleep(1)  # æ¨¡æ‹Ÿæ£€ç´¢æ—¶é—´

            # çŸ¥è¯†æ£€ç´¢
            state = retrieve_knowledge_for_workflow(state)

            await websocket.send_json({
                "type": "thinking_step",
                "step": "æ–¹æ¡ˆç”Ÿæˆ",
                "message": "æ­£åœ¨ç”Ÿæˆè™šæ‹Ÿæ˜Ÿåº§æ–¹æ¡ˆ..."
            })

            await asyncio.sleep(1)  # æ¨¡æ‹Ÿç”Ÿæˆæ—¶é—´

            # ç”Ÿæˆæ–¹æ¡ˆ
            state = await buffered_streaming_planning_nodes.generate_constellation_plan_streaming(state)

        if intent == "generate_plan" and state.main_plan:
            # ç”Ÿæˆå¯è§†åŒ–æ•°æ®

            # å°†å¯è§†åŒ–æ•°æ®æ·»åŠ åˆ°çŠ¶æ€ä¸­

            # åœ¨å“åº”ä¸­æ·»åŠ å¯è§†åŒ–æç¤º
            visualization_prompt = add_visualization_to_response(state)
            if visualization_prompt and state.messages:
                # æ›´æ–°æœ€åä¸€æ¡åŠ©æ‰‹æ¶ˆæ¯
                for msg in reversed(state.messages):
                    if msg.role == "assistant":
                        msg.content += visualization_prompt
                        break

        # 6. æµå¼å‘é€å“åº”
        await stream_response(websocket, state)

        # 7. ä¿å­˜çŠ¶æ€
        await save_conversation_state(state)

        # å‘é€å®Œæˆä¿¡å·æ—¶åŒ…å«å¯è§†åŒ–æ•°æ®
        await websocket.send_json({
            "type": "processing_complete",
            "message": "å¤„ç†å®Œæˆ",
            "visualization_data": state.metadata.get("visualization_data"),
            "extracted_satellites": state.extracted_satellites
        })

    except Exception as e:
        logger.error(f"æµå¼å¤„ç†å‡ºé”™: {str(e)}")
        await websocket.send_json({
            "type": "error",
            "message": f"å¤„ç†å‡ºé”™: {str(e)}"
        })


async def stream_response(websocket: WebSocket, state: WorkflowState):
    """æµå¼å‘é€å“åº”å†…å®¹"""
    # è·å–æœ€æ–°çš„åŠ©æ‰‹æ¶ˆæ¯
    assistant_message = ""
    for msg in reversed(state.messages):
        if msg.role == "assistant":
            assistant_message = msg.content
            break

    if not assistant_message:
        assistant_message = "æŠ±æ­‰ï¼Œæœªèƒ½ç”Ÿæˆæœ‰æ•ˆå›å¤ã€‚"

    # æŒ‰æ®µè½åˆ†å‰²å†…å®¹è¿›è¡Œæµå¼å‘é€
    paragraphs = assistant_message.split('\n\n')

    for i, paragraph in enumerate(paragraphs):
        if paragraph.strip():
            await websocket.send_json({
                "type": "response_chunk",
                "content": paragraph.strip(),
                "chunk_index": i,
                "is_final": i == len(paragraphs) - 1
            })

            # æ·»åŠ å»¶è¿Ÿä½¿æµå¼æ•ˆæœæ›´æ˜æ˜¾
            await asyncio.sleep(0.3)


def analyze_intent_simple(user_message: str, state: WorkflowState) -> str:
    """ç®€åŒ–çš„æ„å›¾åˆ†æ"""
    lower_msg = user_message.lower()

    if any(word in lower_msg for word in ["ç›‘æµ‹", "æ–¹æ¡ˆ", "è®¾è®¡", "è§‚æµ‹", "å«æ˜Ÿ"]):
        return "generate_plan"
    elif any(word in lower_msg for word in ["ä¼˜åŒ–", "æ”¹è¿›", "è°ƒæ•´"]):
        return "optimize_plan"
    elif any(word in lower_msg for word in ["ä»€ä¹ˆæ˜¯", "ä»‹ç»", "è¯´æ˜"]):
        return "provide_info"
    else:
        return "continue_conversation"


async def process_message_async(state: WorkflowState, message: str, websocket: WebSocket):
    """å¼‚æ­¥å¤„ç†æ¶ˆæ¯å¹¶é€šè¿‡WebSocketå‘é€æ›´æ–° - æ”¯æŒæµå¼è¾“å‡º"""
    try:
        # å‘é€å¼€å§‹æ¶ˆæ¯
        await websocket.send_json({"type": "processing_start"})

        # å‘çŠ¶æ€æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        state.add_message("user", message)

        # å®šä¹‰WebSocketå›è°ƒå‡½æ•°
        async def websocket_callback(data):
            """WebSocketæ¶ˆæ¯å‘é€å›è°ƒ"""
            try:
                await websocket.send_json(data)
            except Exception as e:
                logger.error(f"å‘é€WebSocketæ¶ˆæ¯å¤±è´¥: {str(e)}")

        # ä½¿ç”¨æµå¼å·¥ä½œæµå¤„ç†æ¶ˆæ¯
        updated_state, assistant_response = await process_user_input_streaming(
            message,
            state,
            websocket_callback
        )

        # ä¿å­˜å¯¹è¯çŠ¶æ€
        await save_conversation_state(updated_state)

        # å‘é€æœ€ç»ˆå®Œæˆæ¶ˆæ¯
        await websocket.send_json({
            "type": "processing_complete",
            "conversation_id": updated_state.conversation_id,
            "message": assistant_response,
            "plan": updated_state.main_plan
        })

    except asyncio.CancelledError:
        # ä»»åŠ¡è¢«å–æ¶ˆ
        await websocket.send_json({"type": "processing_cancelled"})
        raise

    except Exception as e:
        logger.error(f"å¼‚æ­¥å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™: {str(e)}")
        logger.error(traceback.format_exc())

        # å‘é€é”™è¯¯æ¶ˆæ¯
        await websocket.send_json({
            "type": "error",
            "error": f"å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™: {str(e)}"
        })

        # æ·»åŠ é”™è¯¯å“åº”åˆ°å¯¹è¯
        error_response = f"å¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºé”™ï¼Œè¯·ç¨åé‡è¯•ã€‚é”™è¯¯: {str(e)}"
        state.add_message("assistant", error_response)

        # ä¿å­˜å¯¹è¯çŠ¶æ€
        await save_conversation_state(state        )


# ===== çˆ¬è™«æ™ºèƒ½ä½“APIç«¯ç‚¹ =====

@app.post("/api/crawl/start", response_model=CrawlJobResponse)
async def start_crawl_job(request: CrawlJobRequest, background_tasks: BackgroundTasks):
    """å¯åŠ¨çˆ¬å–ä»»åŠ¡"""
    try:
        logger.info(f"æ”¶åˆ°çˆ¬å–è¯·æ±‚: ç«™ç‚¹{request.target_sites}, å…³é”®è¯{request.keywords}, æœ€å¤§æ•°é‡{request.max_satellites}")
        
        # åˆ›å»ºçˆ¬å–ä»»åŠ¡
        job_id = await crawler_workflow.create_crawl_job(
            target_sites=request.target_sites,
            keywords=request.keywords,
            max_satellites=request.max_satellites
        )
        
        # åœ¨åå°æ‰§è¡Œä»»åŠ¡
        background_tasks.add_task(crawler_workflow.execute_crawl_job, job_id)
        
        return CrawlJobResponse(
            job_id=job_id,
            status="pending",
            message="çˆ¬å–ä»»åŠ¡å·²åˆ›å»ºï¼Œæ­£åœ¨åå°æ‰§è¡Œ",
            estimated_time=request.max_satellites * 2  # ä¼°ç®—æ—¶é—´ï¼ˆç§’ï¼‰
        )
        
    except Exception as e:
        logger.error(f"å¯åŠ¨çˆ¬å–ä»»åŠ¡å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"å¯åŠ¨çˆ¬å–ä»»åŠ¡å¤±è´¥: {str(e)}")


@app.get("/api/crawl/status/{job_id}", response_model=CrawlJobStatusResponse)
async def get_crawl_job_status(job_id: str = PathParam(...)):
    """è·å–çˆ¬å–ä»»åŠ¡çŠ¶æ€"""
    try:
        job_status = crawler_workflow.get_job_status(job_id)
        
        if not job_status:
            raise HTTPException(status_code=404, detail=f"ä»»åŠ¡ä¸å­˜åœ¨: {job_id}")
        
        return CrawlJobStatusResponse(
            job_id=job_status["job_id"],
            status=job_status["status"],
            created_at=job_status["created_at"],
            started_at=job_status.get("started_at"),
            completed_at=job_status.get("completed_at"),
            results=job_status.get("results"),
            error_message=job_status.get("error_message")
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–çˆ¬å–ä»»åŠ¡çŠ¶æ€å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥: {str(e)}")


@app.get("/api/crawl/jobs")
async def list_crawl_jobs(
    status: Optional[str] = Query(None, description="æŒ‰çŠ¶æ€ç­›é€‰: pending, running, completed, failed"),
    limit: int = Query(20, ge=1, le=100)
):
    """è·å–çˆ¬å–ä»»åŠ¡åˆ—è¡¨"""
    try:
        jobs = crawler_workflow.list_jobs(status=status)
        
        # é™åˆ¶è¿”å›æ•°é‡
        jobs = jobs[:limit]
        
        return {
            "jobs": jobs,
            "total": len(jobs)
        }
        
    except Exception as e:
        logger.error(f"è·å–çˆ¬å–ä»»åŠ¡åˆ—è¡¨å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–ä»»åŠ¡åˆ—è¡¨å¤±è´¥: {str(e)}")


@app.get("/api/crawl/logs", response_model=CrawlLogsResponse)
async def get_crawl_logs(
    limit: int = Query(50, ge=1, le=200, description="è¿”å›æ—¥å¿—æ¡æ•°")
):
    """è·å–çˆ¬å–æ—¥å¿—"""
    try:
        logs = await crawler_workflow.get_crawl_logs(limit=limit)
        
        return CrawlLogsResponse(
            logs=logs,
            total=len(logs)
        )
        
    except Exception as e:
        logger.error(f"è·å–çˆ¬å–æ—¥å¿—å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–çˆ¬å–æ—¥å¿—å¤±è´¥: {str(e)}")


@app.get("/api/crawl/statistics", response_model=CrawlStatisticsResponse)
async def get_crawl_statistics(
    days: int = Query(30, ge=1, le=365, description="ç»Ÿè®¡å¤©æ•°")
):
    """è·å–çˆ¬å–ç»Ÿè®¡ä¿¡æ¯"""
    try:
        stats = await crawler_workflow.get_crawl_statistics(days=days)
        
        return CrawlStatisticsResponse(
            total_crawls=stats["total_crawls"],
            total_new_satellites=stats["total_new_satellites"],
            total_failed=stats["total_failed"],
            daily_stats=stats["daily_stats"],
            site_stats=stats["site_stats"],
            recent_logs=stats["recent_logs"]
        )
        
    except Exception as e:
        logger.error(f"è·å–çˆ¬å–ç»Ÿè®¡å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–çˆ¬å–ç»Ÿè®¡å¤±è´¥: {str(e)}")


@app.post("/api/crawl/manual")
async def manual_crawl(
    request: CrawlJobRequest,
    background_tasks: BackgroundTasks
):
    """æ‰‹åŠ¨è§¦å‘çˆ¬å–ï¼ˆç«‹å³æ‰§è¡Œï¼‰"""
    try:
        logger.info(f"æ‰‹åŠ¨çˆ¬å–è¯·æ±‚: ç«™ç‚¹{request.target_sites}")
        
        # åˆ›å»ºå¹¶ç«‹å³æ‰§è¡Œä»»åŠ¡
        job_id = await crawler_workflow.create_crawl_job(
            target_sites=request.target_sites,
            keywords=request.keywords,
            max_satellites=request.max_satellites
        )
        
        # å¼‚æ­¥æ‰§è¡Œä»»åŠ¡
        async def execute_and_log():
            try:
                result = await crawler_workflow.execute_crawl_job(job_id)
                logger.info(f"æ‰‹åŠ¨çˆ¬å–å®Œæˆ: {job_id}, ç»“æœ: {result}")
            except Exception as e:
                logger.error(f"æ‰‹åŠ¨çˆ¬å–å¤±è´¥: {job_id}, é”™è¯¯: {str(e)}")
        
        background_tasks.add_task(execute_and_log)
        
        return {
            "job_id": job_id,
            "message": "æ‰‹åŠ¨çˆ¬å–ä»»åŠ¡å·²å¯åŠ¨",
            "status": "running"
        }
        
    except Exception as e:
        logger.error(f"æ‰‹åŠ¨çˆ¬å–å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ‰‹åŠ¨çˆ¬å–å¤±è´¥: {str(e)}")


# ğŸ†• æ–°å¢ï¼šæ•°æ®å¤„ç†ç›¸å…³çš„æ•°æ®æ¨¡å‹
class DataProcessingRequest(BaseModel):
    """æ•°æ®å¤„ç†è¯·æ±‚æ¨¡å‹"""
    conversation_id: str
    selected_satellites: List[str]
    processing_options: Optional[Dict[str, Any]] = None

class DataProcessingResponse(BaseModel):
    """æ•°æ®å¤„ç†å“åº”æ¨¡å‹"""
    success: bool
    message: str
    processing_id: Optional[str] = None
    progress_url: Optional[str] = None

class ProcessingProgressResponse(BaseModel):
    """å¤„ç†è¿›åº¦å“åº”æ¨¡å‹"""
    processing_id: str
    status: str  # "preparing", "downloading", "processing", "completed", "failed"
    progress: int  # 0-100
    current_stage: str
    message: str
    download_urls: Optional[Dict[str, str]] = None

# ğŸ†• æ–°å¢ï¼šæ•°æ®å¤„ç†APIç«¯ç‚¹

@app.post("/api/process-data", response_model=DataProcessingResponse)
async def process_satellite_data(request: DataProcessingRequest, background_tasks: BackgroundTasks):
    """å¯åŠ¨å«æ˜Ÿæ•°æ®å¤„ç†ï¼ˆè‹¥å¤„ç†å™¨ä¸å¯ç”¨åˆ™è¿”å›æœ€å°å“åº”ï¼‰"""
    try:
        # æœ€å°æ¨¡å¼ï¼šç›´æ¥è¿”å›å›ºå®š processing_id
        if not DATA_PROCESSOR_AVAILABLE:
            return DataProcessingResponse(
                success=True,
                message="æ•°æ®å¤„ç†ä»»åŠ¡å·²å¯åŠ¨(æœ€å°æ¨¡å¼)",
                processing_id="test123",
                progress_url=None
            )

        # æ ‡å‡†æ¨¡å¼ï¼šåˆ›å»ºåå°å¤„ç†ä»»åŠ¡
        processing_id = str(uuid.uuid4())

        processing_tasks[processing_id] = {
            "conversation_id": request.conversation_id,
            "selected_satellites": request.selected_satellites,
            "processing_options": request.processing_options or {},
            "status": "preparing",
            "progress": 0,
            "current_stage": "å‡†å¤‡ä¸­",
            "message": "æ­£åœ¨å‡†å¤‡æ•°æ®å¤„ç†...",
            "start_time": datetime.now().isoformat(),
            "results": None
        }

        background_tasks.add_task(
            execute_data_processing,
            processing_id,
            request.selected_satellites,
            request.processing_options or {}
        )

        return DataProcessingResponse(
            success=True,
            message="æ•°æ®å¤„ç†ä»»åŠ¡å·²å¯åŠ¨",
            processing_id=processing_id,
            progress_url=f"/api/processing-progress/{processing_id}"
        )

    except Exception as e:
        logger.error(f"å¯åŠ¨æ•°æ®å¤„ç†å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å¯åŠ¨æ•°æ®å¤„ç†å¤±è´¥: {str(e)}")

@app.get("/api/processing-progress/{processing_id}", response_model=ProcessingProgressResponse)
async def get_processing_progress(processing_id: str):
    """è·å–æ•°æ®å¤„ç†è¿›åº¦"""
    # å¤„ç†æœ€å°æ¨¡å¼ä¸‹çš„å›ºå®šprocessing_id
    if processing_id == "test123":
        # è¿”å›æ¨¡æ‹Ÿè¿›åº¦æ•°æ®ï¼Œé¿å…å‰ç«¯å´©æºƒ
        return ProcessingProgressResponse(
            processing_id=processing_id,
            status="completed",
            progress=100,
            current_stage="å¤„ç†å®Œæˆ",
            message="æ•°æ®å¤„ç†å·²å®Œæˆï¼(æœ€å°æ¨¡å¼)",
            download_urls={
                "original": "/api/download/original/test123",
                "processed": "/api/download/processed/test123",
                "package": "/api/download/package/test123"
            }
        )
    
    if processing_id not in processing_tasks:
        raise HTTPException(status_code=404, detail="æ‰¾ä¸åˆ°å¤„ç†ä»»åŠ¡")
    
    task = processing_tasks[processing_id]
    
    return ProcessingProgressResponse(
        processing_id=processing_id,
        status=task["status"],
        progress=task["progress"],
        current_stage=task["current_stage"],
        message=task["message"],
        download_urls=task.get("results", {}).get("download_urls") if task.get("results") else None
    )

@app.get("/api/download/{file_type}/{processing_id}")
async def download_processed_data(file_type: str, processing_id: str, preview: bool = Query(False)):
    """ä¸‹è½½å¤„ç†ç»“æœæ–‡ä»¶"""
    # å¤„ç†æœ€å°æ¨¡å¼ä¸‹çš„å›ºå®šprocessing_id
    if processing_id == "test123":
        # è¿”å›æç¤ºä¿¡æ¯ï¼Œå‘ŠçŸ¥ç”¨æˆ·è¿™æ˜¯æœ€å°æ¨¡å¼
        raise HTTPException(
            status_code=400, 
            detail="å½“å‰è¿è¡Œåœ¨æœ€å°æ¨¡å¼ï¼Œè¯·å…ˆå®‰è£…OpenCVä¾èµ–ä»¥å¯ç”¨çœŸå®æ•°æ®å¤„ç†åŠŸèƒ½ã€‚"
            " å®‰è£…å‘½ä»¤ï¼šcd backend && pip install -r requirements.txt"
        )
    
    if processing_id not in processing_tasks:
        raise HTTPException(status_code=404, detail="æ‰¾ä¸åˆ°å¤„ç†ä»»åŠ¡")
    
    task = processing_tasks[processing_id]
    if task["status"] != "completed":
        raise HTTPException(status_code=400, detail="æ•°æ®å¤„ç†å°šæœªå®Œæˆ")
    
    results = task.get("results", {})
    
    if file_type == "original":
        file_path = results.get("original_data")
    elif file_type == "processed":
        file_path = results.get("processed_data")
    elif file_type == "package":
        file_path = results.get("result_package")
    else:
        raise HTTPException(status_code=400, detail="æ— æ•ˆçš„æ–‡ä»¶ç±»å‹")
    
    if not file_path:
        raise HTTPException(status_code=404, detail="æ–‡ä»¶è·¯å¾„ç¼ºå¤±")
    # å…¼å®¹ç›¸å¯¹è·¯å¾„ï¼šè½¬ä¸ºç»å¯¹è·¯å¾„åæ£€æŸ¥
    abs_path = file_path
    if not os.path.isabs(abs_path):
        # ä»¥ settings.data_dir ä¸ºåŸºå‡†
        try:
            from backend.config.config import settings as _settings
            base_dir = _settings.data_dir
        except Exception:
            base_dir = os.getcwd()
        abs_path = os.path.abspath(os.path.join(base_dir, os.path.relpath(file_path)))

    if not os.path.exists(abs_path):
        # å›é€€ï¼šç›´æ¥æ£€æŸ¥åŸå§‹è·¯å¾„
        if not os.path.exists(file_path):
            raise HTTPException(status_code=404, detail=f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        abs_path = file_path
    
    # é¢„è§ˆæ¨¡å¼ï¼šå°†ä»»æ„æ ¼å¼ï¼ˆå¦‚tifï¼‰è½¬ä¸ºPNGå†…è”è¿”å›ï¼Œä¾¿äºå‰ç«¯<img>å±•ç¤º
    if preview:
        try:
            png_bytes: bytes = b""
            try:
                import cv2
                import numpy as np
                img = cv2.imread(abs_path, cv2.IMREAD_UNCHANGED)
                if img is None:
                    raise ValueError("æ— æ³•è¯»å–å›¾åƒç”¨äºé¢„è§ˆ")
                # è‹¥æ˜¯ç°åº¦æˆ–å¸¦Alphaï¼Œå°½é‡è½¬æ¢ä¸ºBGR
                if len(img.shape) == 2:
                    img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
                ok, buf = cv2.imencode('.png', img)
                if not ok:
                    raise ValueError("PNGç¼–ç å¤±è´¥")
                png_bytes = buf.tobytes()
            except Exception:
                # å›é€€åˆ°PIL
                from PIL import Image
                from io import BytesIO
                pil_img = Image.open(abs_path)
                if pil_img.mode not in ('RGB', 'RGBA'):
                    pil_img = pil_img.convert('RGB')
                bio = BytesIO()
                pil_img.save(bio, format='PNG')
                png_bytes = bio.getvalue()
            return Response(content=png_bytes, media_type='image/png')
        except Exception as e:
            logger.error(f"ç”Ÿæˆé¢„è§ˆå¤±è´¥: {e}")
            raise HTTPException(status_code=500, detail=f"ç”Ÿæˆé¢„è§ˆå¤±è´¥: {str(e)}")

    filename = Path(abs_path).name
    return FileResponse(abs_path, filename=filename)

async def execute_data_processing(processing_id: str, selected_satellites: List[str], processing_options: Dict[str, Any]):
    """æ‰§è¡Œæ•°æ®å¤„ç†çš„åå°ä»»åŠ¡"""
    try:
        task = processing_tasks[processing_id]
        # å»¶è¿Ÿå¯¼å…¥ï¼Œé¿å…åœ¨åº”ç”¨å¯åŠ¨æ—¶å› ä¾èµ–é—®é¢˜å¯¼è‡´å¯¼å…¥å¤±è´¥
        try:
            from backend.src.graph.state import SatelliteDataSource, DataProcessingOptions
        except Exception:
            # å…œåº•ï¼šå®šä¹‰è½»é‡å ä½æ¨¡å‹ï¼Œä¿è¯æœ€å°å¯è¿è¡Œ
            from pydantic import BaseModel
            class SatelliteDataSource(BaseModel):
                satellite_name: str
                data_type: str
                download_url: Optional[str] = None
                local_path: Optional[str] = None
            class DataProcessingOptions(BaseModel):
                normalize_illumination: bool = True
                radiometric_correction: bool = True
                atmospheric_correction: bool = False
                geometric_correction: bool = False
                output_format: str = "geotiff"
        
        # å›ºå®šæ ·ä¾‹å›¾åƒè·¯å¾„ï¼šç”±è°ƒç”¨æ–¹é¢„å…ˆæ”¾ç½®æ ·ä¾‹å›¾åƒ
        # è¦æ±‚ï¼šè¯·åœ¨ä»¥ä¸‹è·¯å¾„æ”¾ç½®æ ·ä¾‹å›¾åƒæ–‡ä»¶ï¼šdata/samples/sample_optical.tifï¼ˆé¡¹ç›®æ ¹ç›®å½•ä¸‹ï¼‰
        # è¿™é‡Œä»…ç¡®ä¿ç›®å½•å­˜åœ¨ï¼Œä¸ä¼šè‡ªåŠ¨åˆ›å»ºæ ·ä¾‹å›¾åƒæ–‡ä»¶
        sample_path = os.path.join(settings.data_dir, "samples", "sample_optical.tif")
        os.makedirs(os.path.dirname(sample_path), exist_ok=True)

        # æ›´æ–°çŠ¶æ€ä¸ºä¸‹è½½ä¸­
        task.update({
            "status": "downloading",
            "progress": 10,
            "current_stage": "æ•°æ®è·å–ä¸­",
            "message": "æ­£åœ¨è·å–å«æ˜Ÿæ•°æ®..."
        })
        
        # æ¨¡æ‹Ÿæ•°æ®æºï¼ˆå®é™…åº”ç”¨ä¸­åº”è¯¥ä»æ˜Ÿåº§æ–¹æ¡ˆä¸­è·å–ï¼‰
        data_sources = []
        for satellite in selected_satellites:
            data_source = SatelliteDataSource(
                satellite_name=satellite,
                data_type="optical",
                download_url=None,  # å®é™…åº”ç”¨ä¸­åº”è¯¥æœ‰çœŸå®çš„ä¸‹è½½åœ°å€
                # ä½¿ç”¨å›ºå®šæ ·ä¾‹å›¾åƒè¿›è¡Œåç»­å¤„ç†
                local_path=sample_path
            )
            data_sources.append(data_source)
        
        # æ•°æ®è·å–é˜¶æ®µ (10-50%)
        downloaded_files = []
        for i, data_source in enumerate(data_sources):
            try:
                file_path = await data_processor.download_satellite_data(data_source)
                downloaded_files.append(file_path)
                
                # æ›´æ–°è¿›åº¦
                progress = 10 + int((i + 1) / len(data_sources) * 40)
                task.update({
                    "progress": progress,
                    "message": f"å·²è·å– {i + 1}/{len(data_sources)} ä¸ªå«æ˜Ÿæ•°æ®"
                })
                
            except Exception as e:
                logger.error(f"è·å–æ•°æ®å¤±è´¥ {data_source.satellite_name}: {e}")
                continue
        
        if not downloaded_files:
            raise Exception("æ²¡æœ‰æˆåŠŸè·å–ä»»ä½•æ•°æ®")
        
        # æ›´æ–°çŠ¶æ€ä¸ºå¤„ç†ä¸­
        task.update({
            "status": "processing",
            "progress": 50,
            "current_stage": "æ•°æ®å¤„ç†ä¸­",
            "message": "æ­£åœ¨å¤„ç†å«æ˜Ÿæ•°æ®..."
        })
        
        # æ•°æ®å¤„ç†é˜¶æ®µ (50-90%)
        processing_options_obj = DataProcessingOptions(**processing_options)
        processed_results = []
        
        for i, file_path in enumerate(downloaded_files):
            try:
                result = await data_processor.process_satellite_data(file_path, processing_options_obj)
                processed_results.append(result)
                
                # æ›´æ–°è¿›åº¦
                progress = 50 + int((i + 1) / len(downloaded_files) * 40)
                task.update({
                    "progress": progress,
                    "message": f"å·²å¤„ç† {i + 1}/{len(downloaded_files)} ä¸ªæ•°æ®æ–‡ä»¶"
                })
                
            except Exception as e:
                logger.error(f"å¤„ç†æ•°æ®å¤±è´¥ {file_path}: {e}")
                continue
        
        if not processed_results:
            raise Exception("æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•æ•°æ®")
        
        # å®Œæˆé˜¶æ®µ (90-100%)
        task.update({
            "status": "completed",
            "progress": 100,
            "current_stage": "å¤„ç†å®Œæˆ",
            "message": "æ•°æ®å¤„ç†å®Œæˆï¼",
            "results": {
                "original_data": processed_results[0]["original_data"],
                "processed_data": processed_results[0]["processed_data"],
                "result_package": processed_results[0]["result_package"],
                "download_urls": {
                    "original": f"/api/download/original/{processing_id}",
                    "processed": f"/api/download/processed/{processing_id}",
                    "package": f"/api/download/package/{processing_id}"
                }
            }
        })
        
        logger.info(f"æ•°æ®å¤„ç†ä»»åŠ¡ {processing_id} å®Œæˆ")
        
    except Exception as e:
        logger.error(f"æ•°æ®å¤„ç†ä»»åŠ¡ {processing_id} å¤±è´¥: {e}")
        if processing_id in processing_tasks:
            processing_tasks[processing_id].update({
                "status": "failed",
                "progress": 0,
                "current_stage": "å¤„ç†å¤±è´¥",
                "message": f"æ•°æ®å¤„ç†å¤±è´¥: {str(e)}"
            })

# æœåŠ¡å™¨å¯åŠ¨æ—¶é—´
startup_time = datetime.now().timestamp()

# å½“ç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶æ—¶æ‰§è¡Œæµ‹è¯•
if __name__ == "__main__":
    import uvicorn

    print("=" * 50)
    print("æµ‹è¯•æ™ºæ…§è™šæ‹Ÿæ˜Ÿåº§åŠ©æ‰‹API")
    print("=" * 50)

    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(os.path.join(settings.data_dir, "conversations"), exist_ok=True)

    # ä½¿ç”¨uvicornè¿è¡ŒAPI
    uvicorn.run(
        app,  # ç›´æ¥ä½¿ç”¨appå®ä¾‹
        host="127.0.0.1",  # ä½¿ç”¨æœ¬åœ°å›ç¯åœ°å€
        port=2025,
        
        log_level="info"
    )