# backend/src/rag/knowledge_base.py

import os
import shutil
import time
import logging
from pathlib import Path
from typing import List, Dict, Any, Optional
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from tqdm import tqdm

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger(__name__)

# è·å–é¡¹ç›®æ ¹ç›®å½•
ROOT_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))


# çŸ¥è¯†åº“é…ç½®
class KnowledgeBaseConfig:
    """çŸ¥è¯†åº“é…ç½®"""
    # æ•°æ®ç›®å½•
    data_dir = os.path.join(ROOT_DIR, "backend/data")
    print(f"æ•°æ®ç›®å½•: {data_dir}")
    # çŸ¥è¯†åº“æ–‡æœ¬æ–‡ä»¶è·¯å¾„
    knowledge_file = os.path.join(data_dir, "knowledge", "knowledge.txt")
    # ç´¢å¼•ç›®å½•è·¯å¾„
    index_dir = os.path.join(data_dir, "faiss_indexes")
    # åµŒå…¥æ¨¡å‹åç§°
    embedding_model = "/root/autodl-tmp/virtual star/virtual_constellation_assistant/backend/src/llm/gte-base-zh"


class KnowledgeBase:
    """
    ä½¿ç”¨LangChainå’ŒFAISSå®ç°çš„çŸ¥è¯†åº“ï¼Œç”¨äºå­˜å‚¨å’Œæ£€ç´¢å«æ˜Ÿå’Œé¥æ„Ÿé¢†åŸŸçš„çŸ¥è¯†
    """

    def __init__(self, config=None):
        """åˆå§‹åŒ–çŸ¥è¯†åº“"""
        self.config = config or KnowledgeBaseConfig()
        self.embedding_model_name = self.config.embedding_model
        self.index_dir = self.config.index_dir
        self.knowledge_file = self.config.knowledge_file

        # ç¡®ä¿æ•°æ®ç›®å½•å’Œç´¢å¼•ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(self.knowledge_file), exist_ok=True)
        os.makedirs(self.index_dir, exist_ok=True)

        # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹å’Œå‘é‡å­˜å‚¨
        self.embedding_model = None
        self.vector_store = None

        # åŠ è½½åµŒå…¥æ¨¡å‹
        self._init_embedding_model()

        # åŠ è½½å‘é‡å­˜å‚¨
        self._load_vector_store()

    def _init_embedding_model(self):
        """åˆå§‹åŒ–åµŒå…¥æ¨¡å‹"""
        try:
            logger.info(f"æ­£åœ¨åŠ è½½åµŒå…¥æ¨¡å‹: {self.embedding_model_name}")
            start_time = time.time()
            self.embedding_model = HuggingFaceEmbeddings(model_name=self.embedding_model_name)
            elapsed = time.time() - start_time
            logger.info(f"åµŒå…¥æ¨¡å‹å·²åŠ è½½ï¼Œè€—æ—¶ {elapsed:.2f} ç§’")
        except Exception as e:
            logger.error(f"åŠ è½½åµŒå…¥æ¨¡å‹æ—¶å‡ºé”™: {str(e)}")
            raise

    def _load_vector_store(self):
        """åŠ è½½å‘é‡å­˜å‚¨"""
        index_file = os.path.join(self.index_dir, "index.faiss")
        pkl_file = os.path.join(self.index_dir, "index.pkl")

        if os.path.exists(index_file) and os.path.exists(pkl_file):
            try:
                logger.info(f"æ­£åœ¨ä» {self.index_dir} åŠ è½½FAISSç´¢å¼•")
                start_time = time.time()
                # æ·»åŠ å…è®¸ååºåˆ—åŒ–å‚æ•°
                self.vector_store = FAISS.load_local(
                    self.index_dir,
                    self.embedding_model,
                    allow_dangerous_deserialization=True  # å…è®¸ååºåˆ—åŒ–
                )
                elapsed = time.time() - start_time
                logger.info(f"FAISSç´¢å¼•åŠ è½½å®Œæˆï¼Œè€—æ—¶ {elapsed:.2f} ç§’")
                return True
            except Exception as e:
                logger.error(f"åŠ è½½FAISSç´¢å¼•æ—¶å‡ºé”™: {str(e)}")
                logger.warning("å°†å°è¯•é‡æ–°æ„å»ºç´¢å¼•")
                return False
        else:
            logger.warning(f"FAISSç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨: {index_file}")
            return False

    def _load_documents(self):
        """åŠ è½½æ–‡æ¡£"""
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(self.knowledge_file):
            error_msg = f"é”™è¯¯ï¼šæ–‡ä»¶ {self.knowledge_file} ä¸å­˜åœ¨ï¼è¯·å…ˆåˆ›å»ºè¯¥æ–‡ä»¶ã€‚"
            logger.error(error_msg)
            raise FileNotFoundError(error_msg)

        logger.info("æ­£åœ¨åŠ è½½æ–‡æ¡£...")
        # è¯»å–æ–‡ä»¶å†…å®¹
        with open(self.knowledge_file, 'r', encoding='utf-8') as f:
            content = f.read()

        # åˆ†å‰²æ–‡æ¡£
        docs = content.strip().split("\n\n")
        logger.info(f"å·²åŠ è½½ {len(docs)} æ¡çŸ¥è¯†æè¿°")
        return docs

    def build_index(self, force_rebuild=False):
        """æ„å»ºFAISSç´¢å¼•"""
        # å¦‚æœç´¢å¼•å·²å­˜åœ¨ä¸”ä¸å¼ºåˆ¶é‡å»ºï¼Œåˆ™è·³è¿‡
        if not force_rebuild and self.vector_store is not None:
            logger.info("ç´¢å¼•å·²å­˜åœ¨ï¼Œè·³è¿‡æ„å»º")
            return True

        try:
            # å¦‚æœéœ€è¦é‡å»ºï¼Œå…ˆåˆ é™¤æ—§ç´¢å¼•
            if force_rebuild and os.path.exists(self.index_dir):
                shutil.rmtree(self.index_dir)
                logger.info(f"å·²åˆ é™¤æ—§çš„ç´¢å¼•ç›®å½•: {self.index_dir}")
                os.makedirs(self.index_dir, exist_ok=True)
                logger.info(f"å·²åˆ›å»ºæ–°çš„ç´¢å¼•ç›®å½•: {self.index_dir}")

            # ç¬¬ä¸€æ­¥ï¼šåŠ è½½æ–‡æ¡£
            logger.info("ç¬¬1æ­¥/3ï¼šåŠ è½½æ–‡æ¡£")
            docs = self._load_documents()

            # ç¬¬äºŒæ­¥ï¼šåˆ›å»ºåµŒå…¥å‘é‡å’Œæ„å»ºç´¢å¼•
            logger.info("ç¬¬2æ­¥/3ï¼šåˆ›å»ºæ–‡æ¡£åµŒå…¥å‘é‡å’Œæ„å»ºç´¢å¼•")
            logger.info(f"å¼€å§‹å¤„ç† {len(docs)} æ¡æ–‡æ¡£...")

            start_time = time.time()
            # ä½¿ç”¨tqdmæ˜¾ç¤ºæ–‡æ¡£æ€»æ•°çš„è¿›åº¦
            documents_with_progress = tqdm(docs, desc="å¤„ç†æ–‡æ¡£")

            # æ„å»ºå‘é‡å­˜å‚¨
            self.vector_store = FAISS.from_texts(documents_with_progress, self.embedding_model)

            elapsed = time.time() - start_time
            logger.info(f"å‘é‡ç´¢å¼•æ„å»ºå®Œæˆï¼Œè€—æ—¶ {elapsed:.2f} ç§’")

            # ç¬¬ä¸‰æ­¥ï¼šä¿å­˜ç´¢å¼•
            logger.info("ç¬¬3æ­¥/3ï¼šä¿å­˜ç´¢å¼•åˆ°ç£ç›˜")
            start_time = time.time()
            # ä¿å­˜ç´¢å¼• - ä¸ä½¿ç”¨ä¸æ”¯æŒçš„å‚æ•°
            self.vector_store.save_local(self.index_dir)
            elapsed = time.time() - start_time

            # éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            index_exists = os.path.exists(os.path.join(self.index_dir, "index.faiss"))
            pkl_exists = os.path.exists(os.path.join(self.index_dir, "index.pkl"))

            if index_exists and pkl_exists:
                logger.info(f"ç´¢å¼•å·²æˆåŠŸä¿å­˜è‡³ï¼š{self.index_dir}ï¼Œè€—æ—¶ {elapsed:.2f} ç§’")
                return True
            else:
                logger.error(f"ç´¢å¼•ä¿å­˜å¤±è´¥ï¼Œindex.faisså­˜åœ¨: {index_exists}, index.pklå­˜åœ¨: {pkl_exists}")
                return False

        except Exception as e:
            logger.error(f"æ„å»ºç´¢å¼•æ—¶å‡ºé”™: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())
            return False

    def search(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """
        æœç´¢çŸ¥è¯†åº“

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›çš„æœ€ç›¸å…³ç»“æœæ•°é‡

        Returns:
            åŒ…å«æ–‡æ¡£å†…å®¹å’Œç›¸ä¼¼åº¦çš„ç»“æœåˆ—è¡¨
        """
        if self.vector_store is None:
            logger.warning("å‘é‡å­˜å‚¨æœªåˆå§‹åŒ–ï¼Œæ— æ³•æ‰§è¡Œæœç´¢")
            return []

        try:
            # æ‰§è¡Œç›¸ä¼¼åº¦æœç´¢
            results = self.vector_store.similarity_search_with_score(query, k=top_k)

            # æ ¼å¼åŒ–ç»“æœ
            formatted_results = []
            for doc, score in results:
                # LangChain FAISSè¿”å›çš„åˆ†æ•°å®é™…ä¸Šæ˜¯è·ç¦»ï¼Œè¶Šå°è¶Šç›¸ä¼¼
                # è½¬æ¢ä¸ºç›¸ä¼¼åº¦åˆ†æ•° (0-1èŒƒå›´ï¼Œè¶Šå¤§è¶Šç›¸ä¼¼)
                similarity = 1.0 / (1.0 + score)

                formatted_results.append({
                    "document": doc.page_content,
                    "score": similarity
                })

            return formatted_results

        except Exception as e:
            logger.error(f"æœç´¢æ—¶å‡ºé”™: {str(e)}")
            return []

    def add_texts(self, texts: List[str]) -> bool:
        """
        å‘çŸ¥è¯†åº“æ·»åŠ æ–°æ–‡æœ¬

        Args:
            texts: æ–‡æœ¬åˆ—è¡¨

        Returns:
            æ·»åŠ æ˜¯å¦æˆåŠŸ
        """
        if not texts:
            return False

        if self.vector_store is None:
            logger.warning("å‘é‡å­˜å‚¨æœªåˆå§‹åŒ–ï¼Œæ— æ³•æ·»åŠ æ–‡æœ¬")
            return False

        try:
            # æ·»åŠ æ–‡æœ¬åˆ°å‘é‡å­˜å‚¨
            self.vector_store.add_texts(texts)

            # ä¿å­˜æ›´æ–°åçš„ç´¢å¼•
            self.vector_store.save_local(self.index_dir)

            logger.info(f"æˆåŠŸæ·»åŠ  {len(texts)} æ¡æ–‡æœ¬åˆ°çŸ¥è¯†åº“")
            return True

        except Exception as e:
            logger.error(f"æ·»åŠ æ–‡æœ¬æ—¶å‡ºé”™: {str(e)}")
            return False


# åˆ›å»ºçŸ¥è¯†åº“å•ä¾‹
_knowledge_base_instance = None


def get_knowledge_base() -> KnowledgeBase:
    """è·å–çŸ¥è¯†åº“å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    global _knowledge_base_instance
    if _knowledge_base_instance is None:
        _knowledge_base_instance = KnowledgeBase()
    return _knowledge_base_instance


if __name__ == "__main__":
    """
    è¿™æ®µä»£ç ä»…åœ¨ç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶æ—¶æ‰§è¡Œï¼Œç”¨äºä¸€æ¬¡æ€§æ„å»ºçŸ¥è¯†åº“ç´¢å¼•
    æ„å»ºå®Œæˆåï¼Œåº”ç”¨ç¨‹åºå°†ç›´æ¥åŠ è½½å·²æ„å»ºçš„ç´¢å¼•
    """
    print("=" * 50)
    print("å¼€å§‹æ„å»ºçŸ¥è¯†åº“ç´¢å¼•")
    print("=" * 50)

    # ç¡®ä¿ç›¸å…³ç›®å½•å­˜åœ¨
    kb_config = KnowledgeBaseConfig()

    # æ£€æŸ¥çŸ¥è¯†åº“æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(kb_config.knowledge_file):
        print(f"é”™è¯¯: çŸ¥è¯†åº“æ–‡ä»¶ä¸å­˜åœ¨: {kb_config.knowledge_file}")
        print("è¯·ç¡®ä¿åœ¨ä»¥ä¸‹ä½ç½®åˆ›å»ºçŸ¥è¯†åº“æ–‡ä»¶:")
        print(kb_config.knowledge_file)
        print("\næ–‡ä»¶æ ¼å¼åº”ä¸ºæ–‡æœ¬æ–‡ä»¶ï¼Œæ¯æ®µçŸ¥è¯†ä¹‹é—´ç”¨ç©ºè¡Œåˆ†éš”ã€‚ä¾‹å¦‚ï¼š")
        print("\n---ç¤ºä¾‹æ ¼å¼---")
        print("è¿™æ˜¯ç¬¬ä¸€æ®µå«æ˜ŸçŸ¥è¯†ã€‚è¿™é‡Œå¯ä»¥åŒ…å«å¤šä¸ªå¥å­ã€‚")
        print("")
        print("è¿™æ˜¯ç¬¬äºŒæ®µå«æ˜ŸçŸ¥è¯†ã€‚æ¯æ®µä¹‹é—´ç”¨ç©ºè¡Œåˆ†éš”ã€‚")
        print("---------------")
        exit(1)

    try:
        start_total = time.time()

        # åˆ›å»ºçŸ¥è¯†åº“å®ä¾‹
        kb = KnowledgeBase()

        # é‡æ–°æ„å»ºç´¢å¼•
        print("æ­£åœ¨æ„å»ºç´¢å¼•...")
        success = kb.build_index(force_rebuild=True)

        if success:
            elapsed_total = time.time() - start_total
            print("-" * 50)
            print(f"çŸ¥è¯†åº“ç´¢å¼•æ„å»ºæˆåŠŸ! æ€»è€—æ—¶ï¼š{elapsed_total:.2f} ç§’")
            print("-" * 50)

            # éªŒè¯ç´¢å¼•ç›®å½•å’Œæ–‡ä»¶
            print("\nğŸ“Š æœ€ç»ˆç»“æœéªŒè¯ï¼š")
            index_dir_exists = os.path.exists(kb_config.index_dir)
            if index_dir_exists:
                print(f"âœ… ç´¢å¼•ç›®å½•å·²åˆ›å»ºï¼š{kb_config.index_dir}")
                index_files = os.listdir(kb_config.index_dir)
                print(f"   ç›®å½•å†…å®¹ï¼š{', '.join(index_files)}")

                # æ£€æŸ¥æ–‡ä»¶å¤§å°
                index_size = os.path.getsize(os.path.join(kb_config.index_dir, "index.faiss")) / (1024 * 1024)
                pkl_size = os.path.getsize(os.path.join(kb_config.index_dir, "index.pkl")) / (1024 * 1024)
                print(f"   index.faiss å¤§å°ï¼š{index_size:.2f} MB")
                print(f"   index.pkl å¤§å°ï¼š{pkl_size:.2f} MB")

            # æµ‹è¯•æœç´¢åŠŸèƒ½
            print("\næµ‹è¯•æœç´¢åŠŸèƒ½:")
            test_query = "å«æ˜Ÿé¥æ„ŸæŠ€æœ¯"
            print(f"æŸ¥è¯¢: '{test_query}'")
            results = kb.search(test_query, top_k=3)

            print(f"æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³ç»“æœ:")
            for i, result in enumerate(results):
                print(f"\nç»“æœ {i + 1} (ç›¸ä¼¼åº¦: {result['score']:.4f}):")
                print("-" * 40)
                print(result['document'][:200] + "..." if len(result['document']) > 200 else result['document'])
                print("-" * 40)
        else:
            print("ç´¢å¼•æ„å»ºå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—äº†è§£è¯¦æƒ…")

    except Exception as e:
        print(f"æ„å»ºç´¢å¼•æ—¶å‡ºé”™: {str(e)}")
        import traceback

        traceback.print_exc()
        exit(1)

    print("\nç´¢å¼•å·²æ„å»ºå®Œæˆå¹¶ä¿å­˜åˆ°ç£ç›˜")
    print("ä¸‹æ¬¡åº”ç”¨ç¨‹åºå¯åŠ¨æ—¶å°†ç›´æ¥åŠ è½½æ­¤ç´¢å¼•")
    print("å¦‚éœ€é‡æ–°æ„å»ºç´¢å¼•ï¼Œè¯·å†æ¬¡è¿è¡Œæ­¤æ–‡ä»¶")