# test_satellite_crawler.py

import os
import sys
import asyncio
import json
from pathlib import Path

# ç¡®ä¿é¡¹ç›®æ ¹ç›®å½•åœ¨sys.pathä¸­
current_file = Path(__file__).resolve()
project_root = current_file.parent
sys.path.append(str(project_root))

# æ·»åŠ backendç›®å½•åˆ°sys.path
backend_dir = project_root / "backend"
sys.path.append(str(backend_dir))

try:
    from backend.src.tools.satellite_crawler import SatelliteCrawler
    from backend.src.tools.satellite_data_processor import SatelliteDataProcessor
    print("âœ… æˆåŠŸå¯¼å…¥çˆ¬è™«æ¨¡å—")
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)


async def test_crawler():
    """æµ‹è¯•å«æ˜Ÿçˆ¬è™«åŠŸèƒ½"""
    print("=" * 60)
    print("ğŸš€ å¼€å§‹æµ‹è¯•å«æ˜Ÿçˆ¬è™«åŠŸèƒ½")
    print("=" * 60)
    
    try:
        # 1. æµ‹è¯•çˆ¬è™«åˆå§‹åŒ–
        print("\n1ï¸âƒ£ æµ‹è¯•çˆ¬è™«åˆå§‹åŒ–...")
        crawler = SatelliteCrawler()
        print("âœ… çˆ¬è™«åˆå§‹åŒ–æˆåŠŸ")
        
        # 2. æµ‹è¯•è·å–ä¸»é¡µå†…å®¹
        print("\n2ï¸âƒ£ æµ‹è¯•è·å–ä¸»é¡µå†…å®¹...")
        main_page_content = await crawler.fetch_page(crawler.base_url)
        if main_page_content:
            print(f"âœ… æˆåŠŸè·å–ä¸»é¡µå†…å®¹ï¼Œé•¿åº¦: {len(main_page_content)} å­—ç¬¦")
        else:
            print("âŒ è·å–ä¸»é¡µå†…å®¹å¤±è´¥")
            return
        
        # 3. æµ‹è¯•è§£ææœ€è¿‘å‘å°„åˆ—è¡¨
        print("\n3ï¸âƒ£ æµ‹è¯•è§£ææœ€è¿‘å‘å°„åˆ—è¡¨...")
        recent_satellites = crawler.parse_recent_launches(main_page_content)
        print(f"âœ… è§£æåˆ° {len(recent_satellites)} ä¸ªæœ€è¿‘å‘å°„çš„å«æ˜Ÿ")
        
        if recent_satellites:
            print("\nğŸ“¡ æœ€è¿‘å‘å°„çš„å«æ˜Ÿåˆ—è¡¨ï¼ˆå‰5ä¸ªï¼‰:")
            for i, sat in enumerate(recent_satellites[:5], 1):
                print(f"  {i}. {sat['satellite_name']} ({sat['launch_date']})")
                print(f"     å‘å°„è½½å…·: {sat['vehicle']}")
                print(f"     å‘å°„åœº: {sat['site']}")
                print(f"     è¯¦æƒ…é“¾æ¥: {sat['satellite_url']}")
                print()
        
        # 4. æµ‹è¯•çˆ¬å–å•ä¸ªå«æ˜Ÿè¯¦æƒ…
        if recent_satellites:
            print("\n4ï¸âƒ£ æµ‹è¯•çˆ¬å–å•ä¸ªå«æ˜Ÿè¯¦æƒ…...")
            first_satellite = recent_satellites[0]
            detail_info = await crawler.crawl_satellite_detail(
                first_satellite['satellite_url'], 
                first_satellite['satellite_name']
            )
            
            if detail_info:
                print(f"âœ… æˆåŠŸçˆ¬å–å«æ˜Ÿè¯¦æƒ…: {first_satellite['satellite_name']}")
                print(f"ğŸ“Š è¯¦æƒ…ä¿¡æ¯é”®å€¼å¯¹æ•°é‡: {len(detail_info)}")
                
                # æ˜¾ç¤ºè¯¦æƒ…ä¿¡æ¯
                print("\nğŸ” å«æ˜Ÿè¯¦æƒ…ä¿¡æ¯:")
                for key, value in detail_info.items():
                    if key not in ['raw_content']:  # è·³è¿‡åŸå§‹å†…å®¹
                        print(f"  {key}: {value}")
            else:
                print(f"âŒ çˆ¬å–å«æ˜Ÿè¯¦æƒ…å¤±è´¥: {first_satellite['satellite_name']}")
        
        # 5. æµ‹è¯•æ•°æ®å¤„ç†å™¨
        print("\n5ï¸âƒ£ æµ‹è¯•æ•°æ®å¤„ç†å™¨...")
        processor = SatelliteDataProcessor()
        
        if recent_satellites:
            # å–å‰2ä¸ªå«æ˜Ÿè¿›è¡Œæ ¼å¼åŒ–æµ‹è¯•
            test_data = recent_satellites[:2]
            
            print(f"ğŸ”„ å¼€å§‹æ ¼å¼åŒ– {len(test_data)} ä¸ªå«æ˜Ÿæ•°æ®...")
            formatted_data = await processor.clean_and_format_data(test_data)
            
            if formatted_data:
                print(f"âœ… æˆåŠŸæ ¼å¼åŒ– {len(formatted_data)} ä¸ªå«æ˜Ÿæ•°æ®")
                
                # æ˜¾ç¤ºæ ¼å¼åŒ–åçš„ç¬¬ä¸€ä¸ªå«æ˜Ÿä¿¡æ¯
                if len(formatted_data) > 0:
                    first_formatted = formatted_data[0]
                    print(f"\nğŸ“‹ æ ¼å¼åŒ–åçš„å«æ˜Ÿä¿¡æ¯ç¤ºä¾‹ ({first_formatted.get('satelliteName', 'Unknown')}):")
                    for key, value in first_formatted.items():
                        if key not in ['_crawl_metadata']:
                            print(f"  {key}: {value}")
            else:
                print("âŒ æ•°æ®æ ¼å¼åŒ–å¤±è´¥")
        
        print("\nğŸ‰ æµ‹è¯•å®Œæˆï¼")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
    
    finally:
        # ç¡®ä¿å…³é—­ä¼šè¯
        await crawler.close_session()


async def test_api_endpoints():
    """æµ‹è¯•APIç«¯ç‚¹ï¼ˆæ¨¡æ‹Ÿè¯·æ±‚ï¼‰"""
    print("\n" + "=" * 60)
    print("ğŸŒ APIç«¯ç‚¹åŠŸèƒ½è¯´æ˜")
    print("=" * 60)
    
    endpoints = [
        {
            "method": "POST",
            "path": "/api/satellite/crawl",
            "description": "æ‰§è¡Œå«æ˜Ÿçˆ¬è™«ä»»åŠ¡",
            "example_request": {
                "mode": "recent",
                "max_satellites": 5
            }
        },
        {
            "method": "POST", 
            "path": "/api/satellite/crawl",
            "description": "æœç´¢å•ä¸ªå«æ˜Ÿ",
            "example_request": {
                "mode": "single",
                "satellite_name": "Starlink"
            }
        },
        {
            "method": "GET",
            "path": "/api/satellite/crawl/logs",
            "description": "è·å–çˆ¬è™«æ—¥å¿—åˆ—è¡¨",
            "example_params": "?limit=10&offset=0"
        },
        {
            "method": "GET",
            "path": "/api/satellite/crawl/logs/{filename}",
            "description": "è·å–çˆ¬è™«æ—¥å¿—è¯¦æƒ…",
            "example": "/api/satellite/crawl/logs/satellite_crawl_20250129_143022.json"
        },
        {
            "method": "GET",
            "path": "/api/satellite/data/stats",
            "description": "è·å–å«æ˜Ÿæ•°æ®ç»Ÿè®¡ä¿¡æ¯",
            "returns": "æ–‡ä»¶å¤§å°ã€å«æ˜Ÿæ€»æ•°ã€æœ€åä¿®æ”¹æ—¶é—´ç­‰"
        }
    ]
    
    for i, endpoint in enumerate(endpoints, 1):
        print(f"\n{i}ï¸âƒ£ {endpoint['method']} {endpoint['path']}")
        print(f"   ğŸ“ {endpoint['description']}")
        
        if 'example_request' in endpoint:
            print(f"   ğŸ“¤ è¯·æ±‚ç¤ºä¾‹: {json.dumps(endpoint['example_request'], ensure_ascii=False)}")
        
        if 'example_params' in endpoint:
            print(f"   ğŸ”— å‚æ•°ç¤ºä¾‹: {endpoint['example_params']}")
        
        if 'example' in endpoint:
            print(f"   ğŸŒ è·¯å¾„ç¤ºä¾‹: {endpoint['example']}")
        
        if 'returns' in endpoint:
            print(f"   ğŸ“¥ è¿”å›å†…å®¹: {endpoint['returns']}")


if __name__ == "__main__":
    print("ğŸ¤– å«æ˜Ÿç®¡ç†åŠ©æ‰‹çˆ¬è™«æµ‹è¯•ç¨‹åº")
    print("ğŸŒ ç›®æ ‡ç½‘ç«™: https://space.skyrocket.de")
    print("ğŸ“Š æ•°æ®æ ¼å¼: ç¬¦åˆagent.mdä¸­å®šä¹‰çš„JSONæ ¼å¼")
    print("ğŸ¯ åŠŸèƒ½: çˆ¬å–æœ€è¿‘å‘å°„å«æ˜Ÿ + å•å«æ˜Ÿæœç´¢ + æ•°æ®æ ¼å¼åŒ– + å­˜å‚¨")
    
    # è¿è¡Œçˆ¬è™«æµ‹è¯•
    asyncio.run(test_crawler())
    
    # æ˜¾ç¤ºAPIç«¯ç‚¹ä¿¡æ¯
    asyncio.run(test_api_endpoints())
    
    print("\n" + "=" * 60)
    print("âœ¨ çˆ¬è™«æ™ºèƒ½ä½“å¼€å‘å®Œæˆï¼")
    print("=" * 60)
    print("ğŸš€ å¯åŠ¨æ–¹å¼: python -m backend.main")
    print("ğŸ“š APIæ–‡æ¡£: http://localhost:2025/docs")
    print("ğŸ”— çˆ¬è™«ç«¯ç‚¹: POST /api/satellite/crawl")
    print("ğŸ“Š æ•°æ®ç»Ÿè®¡: GET /api/satellite/data/stats")
    print("ğŸ“ çˆ¬è™«æ—¥å¿—: GET /api/satellite/crawl/logs")
    print("=" * 60)
